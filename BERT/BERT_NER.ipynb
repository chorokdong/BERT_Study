{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1k0w_2bElC4MVT6LugXSONOTPTgBEssEy","authorship_tag":"ABX9TyO8lFcjvsxmKMq8ZgJIroXY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"e15b8d4b822844cd9027f34f1bd13685":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d47844ca1ea64debb1ec38922d08aef6","IPY_MODEL_d995e99aff2b44b29ac5229b5b5a8480","IPY_MODEL_a36ed2eff933434cbc92bc61713bd2e1"],"layout":"IPY_MODEL_fa838b54de6143589a067d4c7d40a048"}},"d47844ca1ea64debb1ec38922d08aef6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c752ccb53a364a9b982834e5c07f2fa0","placeholder":"​","style":"IPY_MODEL_8c532c15d92c44c7840925a686daf343","value":"100%"}},"d995e99aff2b44b29ac5229b5b5a8480":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a82328d869b94ccf94e8960747751d93","max":1182,"min":0,"orientation":"horizontal","style":"IPY_MODEL_123a49a25f8146a085e73b4fcc1e0fe8","value":1182}},"a36ed2eff933434cbc92bc61713bd2e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3001ab50edd4d90ab707777dbfd905b","placeholder":"​","style":"IPY_MODEL_e1aee2d3a670420fbfbc7cf3c77a9359","value":" 1182/1182 [06:59&lt;00:00,  2.98it/s]"}},"fa838b54de6143589a067d4c7d40a048":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c752ccb53a364a9b982834e5c07f2fa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c532c15d92c44c7840925a686daf343":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a82328d869b94ccf94e8960747751d93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"123a49a25f8146a085e73b4fcc1e0fe8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f3001ab50edd4d90ab707777dbfd905b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1aee2d3a670420fbfbc7cf3c77a9359":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29ff09eb5464495994a5920d38b82e9a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f90ecc806dc9447cbc9b6d7ada9da68f","IPY_MODEL_f0e2deebb5344db38ce86c6f12e8fbe3","IPY_MODEL_8d0d935b1f0a4937aa4085268e0f3fd5"],"layout":"IPY_MODEL_d2914c0bf93d4572b69491af9360956f"}},"f90ecc806dc9447cbc9b6d7ada9da68f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29503f4d74b74f0d931755a685f69178","placeholder":"​","style":"IPY_MODEL_d9b50ae13c0a49c0905b1a7bcc2b8cd7","value":"100%"}},"f0e2deebb5344db38ce86c6f12e8fbe3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef0a0d829e854de09e3d1a4b5f61dad6","max":1182,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0590b64900174e85a25c1c897f8fcfb3","value":1182}},"8d0d935b1f0a4937aa4085268e0f3fd5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_448073dccc7e4c298e3773f072c664ee","placeholder":"​","style":"IPY_MODEL_eef78d65df8e4d7a86ce0926187d8a16","value":" 1182/1182 [07:03&lt;00:00,  2.98it/s]"}},"d2914c0bf93d4572b69491af9360956f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29503f4d74b74f0d931755a685f69178":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9b50ae13c0a49c0905b1a7bcc2b8cd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef0a0d829e854de09e3d1a4b5f61dad6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0590b64900174e85a25c1c897f8fcfb3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"448073dccc7e4c298e3773f072c664ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eef78d65df8e4d7a86ce0926187d8a16":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed6f697a45e2480b996e38c3dd46ffa5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_84666c37b9ca4f07ba5b2f08e1208578","IPY_MODEL_3d98ad32232a4906801e5e275fa1f570","IPY_MODEL_f1e1997ecbfa47f2822cfe68e202b1ab"],"layout":"IPY_MODEL_6e658c98ca1d4201a875b1cad76e1805"}},"84666c37b9ca4f07ba5b2f08e1208578":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_385ba1c8ce3545dd86e2cf98cc7114b1","placeholder":"​","style":"IPY_MODEL_dc30446905534e9bb15e9a1978c62e88","value":"100%"}},"3d98ad32232a4906801e5e275fa1f570":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0cd9783f1b83414b996098fc8c60809f","max":1182,"min":0,"orientation":"horizontal","style":"IPY_MODEL_286c74f8fa1c45e990e35a4c7a9ef1f3","value":1182}},"f1e1997ecbfa47f2822cfe68e202b1ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45558df81e274741bda1f77ef36d4d21","placeholder":"​","style":"IPY_MODEL_577c3d329c884c7b92b7f3bf4f53313e","value":" 1182/1182 [07:02&lt;00:00,  2.99it/s]"}},"6e658c98ca1d4201a875b1cad76e1805":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"385ba1c8ce3545dd86e2cf98cc7114b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc30446905534e9bb15e9a1978c62e88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0cd9783f1b83414b996098fc8c60809f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"286c74f8fa1c45e990e35a4c7a9ef1f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45558df81e274741bda1f77ef36d4d21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"577c3d329c884c7b92b7f3bf4f53313e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eeff79342c1540e89dcb7eb41f018ed5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_148559b6b51047a39c7794d21d4d2596","IPY_MODEL_63d5a84821b6407591c988f3cf1645b3","IPY_MODEL_3be2f8c59fd3495e9fc987f02355d6be"],"layout":"IPY_MODEL_1e4d5f5935ca4e2fb74becaf42184daf"}},"148559b6b51047a39c7794d21d4d2596":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8daa72aa98af4f59a982f7d5d68c199d","placeholder":"​","style":"IPY_MODEL_ea7ed472d1d64325bbf5d0ee64946576","value":"100%"}},"63d5a84821b6407591c988f3cf1645b3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d000ae64431469b984f8eacf544dea4","max":132,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ed15440bd8a642f08037db4f11be4271","value":132}},"3be2f8c59fd3495e9fc987f02355d6be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c77279ab353849a6bfd0d95012dccddb","placeholder":"​","style":"IPY_MODEL_171b58daaec64825bf2ee6d02135dd53","value":" 132/132 [00:20&lt;00:00,  6.56it/s]"}},"1e4d5f5935ca4e2fb74becaf42184daf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8daa72aa98af4f59a982f7d5d68c199d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea7ed472d1d64325bbf5d0ee64946576":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d000ae64431469b984f8eacf544dea4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed15440bd8a642f08037db4f11be4271":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c77279ab353849a6bfd0d95012dccddb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"171b58daaec64825bf2ee6d02135dd53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"091abda4322d480a98f2168ed0b31fab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_092cac22d81640b992dca5b14407a14a","IPY_MODEL_8fc97432f1924fc282020bef9118dd99","IPY_MODEL_cb6a1b885cec4c85871c0e1f8c354009"],"layout":"IPY_MODEL_e6f5094e2e2b4345ba7a5f27954227fe"}},"092cac22d81640b992dca5b14407a14a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ec729c738f54575b4327c25baae7291","placeholder":"​","style":"IPY_MODEL_0a3f601de387477ea89bbc1504509be5","value":"100%"}},"8fc97432f1924fc282020bef9118dd99":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bc65a3d12bf46e786f04d038fb8b2a5","max":132,"min":0,"orientation":"horizontal","style":"IPY_MODEL_817b4a2afd0143c19e48b781004d2796","value":132}},"cb6a1b885cec4c85871c0e1f8c354009":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f75ab65d1c46404a9bd2f36a7d1345ed","placeholder":"​","style":"IPY_MODEL_3214491d271f4c2d93d83a64d4599d76","value":" 132/132 [00:24&lt;00:00,  5.49it/s]"}},"e6f5094e2e2b4345ba7a5f27954227fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ec729c738f54575b4327c25baae7291":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a3f601de387477ea89bbc1504509be5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6bc65a3d12bf46e786f04d038fb8b2a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"817b4a2afd0143c19e48b781004d2796":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f75ab65d1c46404a9bd2f36a7d1345ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3214491d271f4c2d93d83a64d4599d76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["---\n","# 0. 필요 라이브러리 설치\n","----"],"metadata":{"id":"3mQHLeNjIEvt"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Z05mEIbiehQ","executionInfo":{"status":"ok","timestamp":1672129865356,"user_tz":-540,"elapsed":7044,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"157422ee-c6b3-442a-eaaf-2b110cdddb27"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.8.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.1.0)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}]},{"cell_type":"markdown","source":["---\n","### 0-1. Klue benckmark 데이터셋 확인\n","----"],"metadata":{"id":"rkxY9wOqJxZn"}},{"cell_type":"code","source":["from datasets import load_dataset\n","from pprint import pprint"],"metadata":{"id":"2Y3RQq4nhYxR","executionInfo":{"status":"ok","timestamp":1672129866495,"user_tz":-540,"elapsed":1145,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["- 데이터셋 다운"],"metadata":{"id":"Gtd3jr0gH9Ov"}},{"cell_type":"code","source":["dataset = load_dataset(\"klue\", \"ner\", split=\"train\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u07V8sqziwBt","executionInfo":{"status":"ok","timestamp":1672129867454,"user_tz":-540,"elapsed":961,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"ab6e111b-f97a-44a8-a9bb-aa1f7c4834d7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset klue (/root/.cache/huggingface/datasets/klue/ner/1.0.0/e0fc3bc3de3eb03be2c92d72fd04a60ecc71903f821619cb28ca0e1e29e4233e)\n"]}]},{"cell_type":"markdown","source":["- 데이터 구성 확인"],"metadata":{"id":"QMx2Z9G6IOVj"}},{"cell_type":"code","source":["dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TLv1NwjmIP5B","executionInfo":{"status":"ok","timestamp":1672129867454,"user_tz":-540,"elapsed":12,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"eb12e6d7-9cac-4d6c-c2e0-6d1c59dee08e"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['sentence', 'tokens', 'ner_tags'],\n","    num_rows: 21008\n","})"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["dataset.info.__dict__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vNfADmPMITiX","executionInfo":{"status":"ok","timestamp":1672129867454,"user_tz":-540,"elapsed":10,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"56b92640-337a-40d6-b964-74e748ee6772"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'description': 'KLUE (Korean Language Understanding Evaluation)\\nKorean Language Understanding Evaluation (KLUE) benchmark is a series of datasets to evaluate natural language\\nunderstanding capability of Korean language models. KLUE consists of 8 diverse and representative tasks, which are accessible\\nto anyone without any restrictions. With ethical considerations in mind, we deliberately design annotation guidelines to obtain\\nunambiguous annotations for all datasets. Futhermore, we build an evaluation system and carefully choose evaluations metrics\\nfor every task, thus establishing fair comparison across Korean language models.\\n',\n"," 'citation': '@misc{park2021klue,\\n      title={KLUE: Korean Language Understanding Evaluation},\\n      author={Sungjoon Park and Jihyung Moon and Sungdong Kim and Won Ik Cho and Jiyoon Han and Jangwon Park and Chisung Song and Junseong Kim and Yongsook Song and Taehwan Oh and Joohong Lee and Juhyun Oh and Sungwon Lyu and Younghoon Jeong and Inkwon Lee and Sangwoo Seo and Dongjun Lee and Hyunwoo Kim and Myeonghwa Lee and Seongbo Jang and Seungwon Do and Sunkyoung Kim and Kyungtae Lim and Jongwon Lee and Kyumin Park and Jamin Shin and Seonghyun Kim and Lucy Park and Alice Oh and Jungwoo Ha and Kyunghyun Cho},\\n      year={2021},\\n      eprint={2105.09680},\\n      archivePrefix={arXiv},\\n      primaryClass={cs.CL}\\n}\\n',\n"," 'homepage': 'https://klue-benchmark.com/tasks/69/overview/description',\n"," 'license': 'CC-BY-SA-4.0',\n"," 'features': {'sentence': Value(dtype='string', id=None),\n","  'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n","  'ner_tags': Sequence(feature=ClassLabel(names=['B-DT', 'I-DT', 'B-LC', 'I-LC', 'B-OG', 'I-OG', 'B-PS', 'I-PS', 'B-QT', 'I-QT', 'B-TI', 'I-TI', 'O'], id=None), length=-1, id=None)},\n"," 'post_processed': None,\n"," 'supervised_keys': None,\n"," 'task_templates': None,\n"," 'builder_name': 'klue',\n"," 'config_name': 'ner',\n"," 'version': 1.0.0,\n"," 'splits': {'train': SplitInfo(name='train', num_bytes=19891905, num_examples=21008, shard_lengths=None, dataset_name='klue'),\n","  'validation': SplitInfo(name='validation', num_bytes=4937563, num_examples=5000, shard_lengths=None, dataset_name='klue')},\n"," 'download_checksums': {'http://klue-benchmark.com.s3.amazonaws.com/app/Competitions/000069/data/klue-ner-v1.tar.gz': {'num_bytes': 4308644,\n","   'checksum': '848a89759ac6b7c149c9a00d820726fe2a140c22782201f1a40d856672e7ea8e'}},\n"," 'download_size': 4308644,\n"," 'post_processing_size': None,\n"," 'dataset_size': 24829468,\n"," 'size_in_bytes': 29138112}"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["print(f\"Dataset 개수: {len(dataset)}\\n\")\n","print(\"1번째 아이템 :\")\n","print()\n","print(dataset[0][\"sentence\"])\n","print(dataset[0][\"tokens\"])\n","print(dataset[0][\"ner_tags\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cwUhaOO5IT1D","executionInfo":{"status":"ok","timestamp":1672129867454,"user_tz":-540,"elapsed":6,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"21c048ca-3760-474d-e9c3-65f427d58673"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset 개수: 21008\n","\n","1번째 아이템 :\n","\n","특히 <영동고속도로:LC> <강릉:LC> 방향 <문막휴게소:LC>에서 <만종분기점:LC>까지 <5㎞:QT> 구간에는 승용차 전용 임시 갓길차로제를 운영하기로 했다.\n","['특', '히', ' ', '영', '동', '고', '속', '도', '로', ' ', '강', '릉', ' ', '방', '향', ' ', '문', '막', '휴', '게', '소', '에', '서', ' ', '만', '종', '분', '기', '점', '까', '지', ' ', '5', '㎞', ' ', '구', '간', '에', '는', ' ', '승', '용', '차', ' ', '전', '용', ' ', '임', '시', ' ', '갓', '길', '차', '로', '제', '를', ' ', '운', '영', '하', '기', '로', ' ', '했', '다', '.']\n","[12, 12, 12, 2, 3, 3, 3, 3, 3, 12, 2, 3, 12, 12, 12, 12, 2, 3, 3, 3, 3, 12, 12, 12, 2, 3, 3, 3, 3, 12, 12, 12, 8, 9, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n"]}]},{"cell_type":"markdown","source":["- Tag와 Token 매칭 시켜서 확인"],"metadata":{"id":"qABwc1vZIqdp"}},{"cell_type":"code","source":["for token, tag in zip(dataset[0][\"tokens\"], dataset[0][\"ner_tags\"]):\n","  print(token, tag)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0YBBFt6yIZPz","executionInfo":{"status":"ok","timestamp":1672129868177,"user_tz":-540,"elapsed":725,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"9863326e-e967-4fe9-e789-1acf30fb9f52"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["특 12\n","히 12\n","  12\n","영 2\n","동 3\n","고 3\n","속 3\n","도 3\n","로 3\n","  12\n","강 2\n","릉 3\n","  12\n","방 12\n","향 12\n","  12\n","문 2\n","막 3\n","휴 3\n","게 3\n","소 3\n","에 12\n","서 12\n","  12\n","만 2\n","종 3\n","분 3\n","기 3\n","점 3\n","까 12\n","지 12\n","  12\n","5 8\n","㎞ 9\n","  12\n","구 12\n","간 12\n","에 12\n","는 12\n","  12\n","승 12\n","용 12\n","차 12\n","  12\n","전 12\n","용 12\n","  12\n","임 12\n","시 12\n","  12\n","갓 12\n","길 12\n","차 12\n","로 12\n","제 12\n","를 12\n","  12\n","운 12\n","영 12\n","하 12\n","기 12\n","로 12\n","  12\n","했 12\n","다 12\n",". 12\n"]}]},{"cell_type":"markdown","source":["- NER_Tag 확인"],"metadata":{"id":"rzRwjdSII1yk"}},{"cell_type":"code","source":["dataset.features[\"ner_tags\"].feature.names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OklJ06brItfd","executionInfo":{"status":"ok","timestamp":1672129868178,"user_tz":-540,"elapsed":11,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"7dd97a22-24d2-4870-a06b-76418513df7a"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['B-DT',\n"," 'I-DT',\n"," 'B-LC',\n"," 'I-LC',\n"," 'B-OG',\n"," 'I-OG',\n"," 'B-PS',\n"," 'I-PS',\n"," 'B-QT',\n"," 'I-QT',\n"," 'B-TI',\n"," 'I-TI',\n"," 'O']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["label_list = dataset.features[\"ner_tags\"].feature.names\n","label2index = {label: i for i, label in enumerate(label_list)}\n","index2label = {i: label for label, i in label2index.items()}"],"metadata":{"id":"EVenu2qtI4T0","executionInfo":{"status":"ok","timestamp":1672129868179,"user_tz":-540,"elapsed":8,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["index2label"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k7QQCYUcJPyj","executionInfo":{"status":"ok","timestamp":1672129868179,"user_tz":-540,"elapsed":8,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"7613a840-9fc5-4c08-f7d0-c64878e85348"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 'B-DT',\n"," 1: 'I-DT',\n"," 2: 'B-LC',\n"," 3: 'I-LC',\n"," 4: 'B-OG',\n"," 5: 'I-OG',\n"," 6: 'B-PS',\n"," 7: 'I-PS',\n"," 8: 'B-QT',\n"," 9: 'I-QT',\n"," 10: 'B-TI',\n"," 11: 'I-TI',\n"," 12: 'O'}"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["- character 값을 Label string으로 변경"],"metadata":{"id":"ZIbuJWEXJj1a"}},{"cell_type":"code","source":["for token, tag in zip(dataset[0][\"tokens\"], dataset[0][\"ner_tags\"]):\n","  print(token, index2label[tag])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jrkv4TnTJQFK","executionInfo":{"status":"ok","timestamp":1672129868179,"user_tz":-540,"elapsed":6,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"7afccec2-d873-4633-e5a2-326794863871"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["특 O\n","히 O\n","  O\n","영 B-LC\n","동 I-LC\n","고 I-LC\n","속 I-LC\n","도 I-LC\n","로 I-LC\n","  O\n","강 B-LC\n","릉 I-LC\n","  O\n","방 O\n","향 O\n","  O\n","문 B-LC\n","막 I-LC\n","휴 I-LC\n","게 I-LC\n","소 I-LC\n","에 O\n","서 O\n","  O\n","만 B-LC\n","종 I-LC\n","분 I-LC\n","기 I-LC\n","점 I-LC\n","까 O\n","지 O\n","  O\n","5 B-QT\n","㎞ I-QT\n","  O\n","구 O\n","간 O\n","에 O\n","는 O\n","  O\n","승 O\n","용 O\n","차 O\n","  O\n","전 O\n","용 O\n","  O\n","임 O\n","시 O\n","  O\n","갓 O\n","길 O\n","차 O\n","로 O\n","제 O\n","를 O\n","  O\n","운 O\n","영 O\n","하 O\n","기 O\n","로 O\n","  O\n","했 O\n","다 O\n",". O\n"]}]},{"cell_type":"markdown","source":["---\n","### 0-2. Klue/Bert-base 확인\n","----"],"metadata":{"id":"8o0CXSQHJ3hv"}},{"cell_type":"code","source":["from pathlib import Path\n","from pprint import pprint\n","from transformers import AutoModel, AutoTokenizer\n","from transformers import PreTrainedTokenizer, BertConfig, BertForTokenClassification\n","from typing import Dict, List, Union\n","from tqdm import tqdm\n","\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","\n","model = AutoModel.from_pretrained(\"klue/bert-base\")\n","tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n","\n","max_length = 128\n","batch_size = 16"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zETnz2XCpr4s","executionInfo":{"status":"ok","timestamp":1672129872923,"user_tz":-540,"elapsed":4748,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"573c8f1d-e9ef-443f-f4f5-25601726bfd6"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["text = \"7월 고양에서 열린 친선경기에서 손흥민은\"\n","print(tokenizer(text).encodings, '\\n')\n","print(tokenizer.tokenize(text), '\\n')\n","tokens = tokenizer(text).encodings[0].tokens\n","tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8OnQEdNgp0jd","executionInfo":{"status":"ok","timestamp":1672129873837,"user_tz":-540,"elapsed":31,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"792b54ea-718d-4888-d7f6-5fbefc2b2e5c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["[Encoding(num_tokens=12, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])] \n","\n","['7', '##월', '고양', '##에서', '열린', '친선', '##경기', '##에서', '손흥민', '##은'] \n","\n"]},{"output_type":"execute_result","data":{"text/plain":["['[CLS]',\n"," '7',\n"," '##월',\n"," '고양',\n"," '##에서',\n"," '열린',\n"," '친선',\n"," '##경기',\n"," '##에서',\n"," '손흥민',\n"," '##은',\n"," '[SEP]']"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["---\n","# 1. Dataset 구축하기\n","----"],"metadata":{"id":"SMoOT_N0Ktt8"}},{"cell_type":"code","source":["file_path = Path(\"/content/drive/MyDrive/2_Leture/0_Fast_Campus_NLP/Project_5_NER/klue-ner-v1.1/klue-ner-v1.1_dev_sample_10.tsv\")"],"metadata":{"id":"XfsKmZFmua8A","executionInfo":{"status":"ok","timestamp":1672129873837,"user_tz":-540,"elapsed":29,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["file_text = file_path.read_text().strip()\n","pprint(file_text[:300])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cUz-i6YFUCM-","executionInfo":{"status":"ok","timestamp":1672129873838,"user_tz":-540,"elapsed":29,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"027342b6-c6f8-4fea-fb0e-eea40ffff3a3"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["('## 토큰, 레이블 구분자 : \\\\t\\n'\n"," '## 토큰 구분자 : \\\\n\\n'\n"," '## 문장 구분자 : \\\\n\\\\n\\n'\n"," '## 주석 : ##\\n'\n"," '## 컬럼명 : CHAR\\tNE_TAG\\n'\n"," '## klue-ner-v1_dev_00000-wikitree\\t<경찰:OG>은 또 성매매 알선 자금을 관리한 <박:PS>씨의 '\n"," '딸(<32:QT>)과 성매매 여성 <김:PS>모(<33:QT>)씨 등 <16명:QT>을 같은 혐의로 불구속 입건했다.\\n'\n"," '경\\tB-OG\\n'\n"," '찰\\tI-OG\\n'\n"," '은\\tO\\n'\n"," ' \\tO\\n'\n"," '또\\tO\\n'\n"," ' \\tO\\n'\n"," '성\\tO\\n'\n"," '매\\tO\\n'\n"," '매\\tO\\n'\n"," ' \\tO\\n'\n"," '알\\tO\\n'\n"," '선\\tO\\n'\n"," ' \\tO\\n'\n"," '자\\tO\\n'\n"," '금\\tO\\n'\n"," '을\\tO\\n'\n"," ' \\tO\\n'\n"," '관\\tO\\n'\n"," '리\\tO')\n"]}]},{"cell_type":"markdown","source":["- NER data는 음절단위로 구성되어 있지만 학습을 위해서는 토큰(어절) 단위로 변경이 필요"],"metadata":{"id":"1y39Flo2N2D8"}},{"cell_type":"code","source":["sentences = file_text.split(\"\\n\\n\")\n","sentence = \"\"\n","char_labels = []\n","for line in sentences[5].split(\"\\n\"):\n","    if line.startswith(\"##\"): # 샵 두개있는건\n","      continue # 무시\n","    token, tag = line.split(\"\\t\") # 가지고올 문장은 \\t 단위로 구분됨\n","    sentence += token\n","    char_labels.append(tag) # 음정단위 Label 저장\n","print(sentence)\n","print(char_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UQQ4NllNMbnp","executionInfo":{"status":"ok","timestamp":1672129873838,"user_tz":-540,"elapsed":26,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"d346cd7a-3e28-4fae-8d92-a3d50c5a23ab"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["18번 홀(파5)에서 열린 연장 첫 번째 홀에서 파를 지킨 최운정은 보기에 그친 장하나를 따돌리고 LPGA 투어 첫 우승의 감격을 누렸다.\n","['B-QT', 'I-QT', 'I-QT', 'I-QT', 'I-QT', 'O', 'B-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'I-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OG', 'I-OG', 'I-OG', 'I-OG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"]}]},{"cell_type":"markdown","source":["- Tokenizer의 Offset을 활용하면 Token level로 input을 구성할 수 있다"],"metadata":{"id":"KuL5DQ1KPOKO"}},{"cell_type":"code","source":["tokenizer(text, return_offsets_mapping = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3JGQdCk4QxqL","executionInfo":{"status":"ok","timestamp":1672129873838,"user_tz":-540,"elapsed":22,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"db20c30e-f8e9-4770-ef9e-ee4b7f7a0f64"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [2, 27, 2429, 5307, 27135, 4306, 19934, 10470, 27135, 11251, 2073, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 1), (1, 2), (3, 5), (5, 7), (8, 10), (11, 13), (13, 15), (15, 17), (18, 21), (21, 22), (0, 0)]}"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# offset sample\n","offset_mappings = tokenizer(text, return_offsets_mapping = True)['offset_mapping']\n","offset_mappings"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0tDOmT4rOVY-","executionInfo":{"status":"ok","timestamp":1672129873838,"user_tz":-540,"elapsed":19,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"d675cb32-82fc-49ea-8a8e-d03b80c9bdf6"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 0),\n"," (0, 1),\n"," (1, 2),\n"," (3, 5),\n"," (5, 7),\n"," (8, 10),\n"," (11, 13),\n"," (13, 15),\n"," (15, 17),\n"," (18, 21),\n"," (21, 22),\n"," (0, 0)]"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["print(text,'\\n')\n","for token, offset_mapping in zip(tokens, offset_mappings):\n","  print(token, offset_mapping)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6CRGEEdcPsuf","executionInfo":{"status":"ok","timestamp":1672129873839,"user_tz":-540,"elapsed":19,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"8ed7ff89-20ce-4a59-e928-375267ca4a25"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["7월 고양에서 열린 친선경기에서 손흥민은 \n","\n","[CLS] (0, 0)\n","7 (0, 1)\n","##월 (1, 2)\n","고양 (3, 5)\n","##에서 (5, 7)\n","열린 (8, 10)\n","친선 (11, 13)\n","##경기 (13, 15)\n","##에서 (15, 17)\n","손흥민 (18, 21)\n","##은 (21, 22)\n","[SEP] (0, 0)\n"]}]},{"cell_type":"markdown","source":["![이미지](https://drive.google.com/uc?id=14NhWI-fdTSAJrFRCikclqsnVYe8n3qcM)\n","- 각 음절단위가 시작하는 start_offset을 활용해 character_label의 start_index로 사용해 token_label로 사용"],"metadata":{"id":"FPWNaqqaRAYr"}},{"cell_type":"code","source":["token_labels = []\n","offset_mappings = tokenizer(sentence, return_offsets_mapping=True)[\"offset_mapping\"]\n","\n","for offset in offset_mappings: \n","    start, end = offset\n","    if start == end == 0:\n","        continue\n","    token_labels.append(char_labels[start])\n","\n","print(token_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NtBkVaDeQ39Z","executionInfo":{"status":"ok","timestamp":1672129873839,"user_tz":-540,"elapsed":18,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"8d153ccb-d6e3-48c7-c7b5-6af32ec8dc88"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["['B-QT', 'I-QT', 'I-QT', 'O', 'B-QT', 'I-QT', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'B-PS', 'I-PS', 'O', 'O', 'O', 'B-OG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"]}]},{"cell_type":"markdown","source":["- 기존 Token과 매칭 되는지 확인"],"metadata":{"id":"JxanNzkTRnCJ"}},{"cell_type":"code","source":["print(sentence)\n","print(char_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Dm8YM2lR6f4","executionInfo":{"status":"ok","timestamp":1672129873839,"user_tz":-540,"elapsed":16,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"5f2fe041-9f05-4f1f-9c23-5f827c834fa9"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["18번 홀(파5)에서 열린 연장 첫 번째 홀에서 파를 지킨 최운정은 보기에 그친 장하나를 따돌리고 LPGA 투어 첫 우승의 감격을 누렸다.\n","['B-QT', 'I-QT', 'I-QT', 'I-QT', 'I-QT', 'O', 'B-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'I-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OG', 'I-OG', 'I-OG', 'I-OG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"]}]},{"cell_type":"code","source":["tokens = tokenizer.tokenize(sentence)\n","for token, label in zip(tokens, token_labels):\n","    print(f\"{token}\\t{label}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1I9ibsFLRi8I","executionInfo":{"status":"ok","timestamp":1672129873840,"user_tz":-540,"elapsed":16,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"5ec5e736-a8b0-44a3-9cd3-a654a7e3ae90"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["18\tB-QT\n","##번\tI-QT\n","홀\tI-QT\n","(\tO\n","파\tB-QT\n","##5\tI-QT\n",")\tO\n","에서\tO\n","열린\tO\n","연장\tO\n","첫\tB-QT\n","번\tI-QT\n","##째\tI-QT\n","홀\tO\n","##에서\tO\n","파\tO\n","##를\tO\n","지킨\tO\n","최\tB-PS\n","##운\tI-PS\n","##정\tI-PS\n","##은\tO\n","보\tO\n","##기에\tO\n","그친\tO\n","장하\tB-PS\n","##나\tI-PS\n","##를\tO\n","따돌리\tO\n","##고\tO\n","LPGA\tB-OG\n","투어\tO\n","첫\tO\n","우승\tO\n","##의\tO\n","감격\tO\n","##을\tO\n","누렸\tO\n","##다\tO\n",".\tO\n"]}]},{"cell_type":"code","source":["labels = [\n","    \"B-PS\",\n","    \"I-PS\",\n","    \"B-LC\",\n","    \"I-LC\",\n","    \"B-OG\",\n","    \"I-OG\",\n","    \"B-DT\",\n","    \"I-DT\",\n","    \"B-TI\",\n","    \"I-TI\",\n","    \"B-QT\",\n","    \"I-QT\",\n","    \"O\",\n","]"],"metadata":{"id":"UPld_U7WZpg7","executionInfo":{"status":"ok","timestamp":1672129873840,"user_tz":-540,"elapsed":14,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# String label값을 tensor로 변환하기 위해\n","label2id = {label: i for i, label in enumerate(labels)}\n","id2label = {i: label for label, i in label2id.items()}"],"metadata":{"id":"UDCtb1YArCTj","executionInfo":{"status":"ok","timestamp":1672129873840,"user_tz":-540,"elapsed":14,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["---\n","### 1-1. Dataloader\n","---"],"metadata":{"id":"Fsien2erVVEN"}},{"cell_type":"code","source":["def load_data(file_path: str, tokenizer: PreTrainedTokenizer = None):\n","    klue_data = Path(file_path)\n","    klue_text = klue_data.read_text().strip()\n","    documents = klue_text.split(\"\\n\\n\")\n","\n","    data_list = []\n","    for doc in documents:\n","        char_labels = [] \n","        token_labels = []\n","        chars = []\n","        sentence = \"\"\n","        for line in doc.split(\"\\n\"):\n","            if line.startswith(\"##\"):\n","                continue\n","            token, tag = line.split(\"\\t\")\n","            sentence += token\n","            char_labels.append(tag)\n","            chars.append(token)\n","        \n","        offset_mappings = tokenizer(sentence, return_offsets_mapping=True)[\"offset_mapping\"]\n","        for offset in offset_mappings:\n","            start, end = offset\n","            if start == end == 0:\n","                continue\n","            token_labels.append(char_labels[start])\n","\n","        instance = {\n","            \"sentence\": sentence,\n","            \"token_label\": token_labels,\n","            \"char_label\": char_labels,\n","            \"offset_mapping\": offset_mappings\n","        }\n","        data_list.append(instance)\n","\n","    return data_list"],"metadata":{"id":"YwlnAuE-I8vr","executionInfo":{"status":"ok","timestamp":1672129873840,"user_tz":-540,"elapsed":14,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["---\n","### 1-2. dataset\n","---"],"metadata":{"id":"ypgBwiZNJ5il"}},{"cell_type":"code","source":["class NerDataset(Dataset):\n","    def __init__(\n","        self,\n","        tokenizer: PreTrainedTokenizer,\n","        examples: List,\n","        shuffle: bool = False,\n","        **kwargs\n","    ):\n","        self.dataset = examples\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, index):\n","        instance = self.dataset[index]\n","\n","        return instance"],"metadata":{"id":"f0NLQ15-KHYO","executionInfo":{"status":"ok","timestamp":1672129873840,"user_tz":-540,"elapsed":14,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def collate_fn(input_examples):\n","  input_texts, input_labels_str = [], []\n","  offset_mappings = []\n","  char_labels = []\n","\n","  for input_example in input_examples:\n","      text, label_strs = input_example[\"sentence\"], input_example[\"token_label\"]\n","      input_texts.append(text)\n","      input_labels_str.append(label_strs)\n","      offset_mappings.append(input_example[\"offset_mapping\"])\n","      char_labels.append(input_example[\"char_label\"])\n","\n","  encoded_texts = tokenizer.batch_encode_plus( # batch_encode_plus\n","      input_texts,\n","      add_special_tokens=True,\n","      max_length=max_length,\n","      truncation=True,\n","      padding=\"max_length\",\n","      return_tensors=\"pt\",\n","      return_token_type_ids=True,\n","      return_attention_mask=True,\n","      return_offsets_mapping=True\n","  )\n","  input_ids = encoded_texts[\"input_ids\"]\n","  token_type_ids = encoded_texts[\"token_type_ids\"]\n","  attention_mask = encoded_texts[\"attention_mask\"]\n","\n","  len_input = input_ids.size(1)\n","  input_labels = []\n","  for input_label_str in input_labels_str:\n","      input_label = [label2id[x] for x in input_label_str]\n","      input_label = (\n","          [-100] + input_label + (len_input - len(input_label_str) - 1) * [-100]\n","      )\n","      input_label = torch.tensor(input_label).long()\n","      input_labels.append(input_label)\n","\n","  input_labels = torch.stack(input_labels)\n","  return input_ids, token_type_ids, attention_mask, input_labels, offset_mappings, char_labels"],"metadata":{"id":"lvT4TMMmKK2K","executionInfo":{"status":"ok","timestamp":1672129873841,"user_tz":-540,"elapsed":15,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["---\n","# 2. Hyperparameter 설정하기\n","----"],"metadata":{"id":"jghYbPnjSxXH"}},{"cell_type":"code","source":["from pathlib import Path\n","from pprint import pprint\n","from transformers import AutoModel, AutoTokenizer\n","from transformers import PreTrainedTokenizer, BertConfig, BertForTokenClassification\n","from typing import Dict, List, Union\n","from tqdm.notebook import tqdm"],"metadata":{"id":"eQwD9ut3ThoC","executionInfo":{"status":"ok","timestamp":1672129873841,"user_tz":-540,"elapsed":15,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# 데이터를 담아놓는 파이썬 클래스 모듈 \n","from dataclasses import dataclass\n","\n","@dataclass\n","class Config():\n","  model_name: str = \"klue/bert-base\"\n","  train_data: str = \"/content/drive/MyDrive/2_Leture/0_Fast_Campus_NLP/Project_5_NER/klue-ner-v1.1/klue-ner-v1.1_train.tsv\"\n","  test_data: str = \"/content/drive/MyDrive/2_Leture/0_Fast_Campus_NLP/Project_5_NER/klue-ner-v1.1/klue-ner-v1.1_dev.tsv\"\n","  epoch: int = 3\n","  max_seq_len: int = 510\n","  batch_size: int = 24\n","  learning_rate: float = 1e-3\n","  adam_epsilon: float = 1e-8\n","  device: str = \"cuda\"\n","  max_grad_norm: float = 1.0"],"metadata":{"id":"58sHP0cfS0eS","executionInfo":{"status":"ok","timestamp":1672129873841,"user_tz":-540,"elapsed":14,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# 확인\n","init_config = Config()"],"metadata":{"id":"fLPcSHyMTPjp","executionInfo":{"status":"ok","timestamp":1672129873841,"user_tz":-540,"elapsed":14,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["init_config.model_name"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"YD5FEyxkYbyc","executionInfo":{"status":"ok","timestamp":1672129873841,"user_tz":-540,"elapsed":14,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"6d20e950-c7b8-49b3-eb2c-3af13e9acee2"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'klue/bert-base'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["- config를 활용해 불러올 수 있음"],"metadata":{"id":"IZILK8kwTYc4"}},{"cell_type":"code","source":["config = BertConfig.from_pretrained(init_config.model_name, num_labels=len(label2id))"],"metadata":{"id":"OBCVupBoW3Bq","executionInfo":{"status":"ok","timestamp":1672129874307,"user_tz":-540,"elapsed":479,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["- BertConfig와 config가 헷갈리니 하나에 몰아주기"],"metadata":{"id":"8kQMK8paTw5t"}},{"cell_type":"code","source":["config.update(init_config.__dict__)"],"metadata":{"id":"aomr4LmXXN5g","executionInfo":{"status":"ok","timestamp":1672129874308,"user_tz":-540,"elapsed":7,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jvqfJvSLT1jT","executionInfo":{"status":"ok","timestamp":1672129874308,"user_tz":-540,"elapsed":6,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"96118460-7b89-4c22-9dcb-ea1f9fe4227e"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertConfig {\n","  \"adam_epsilon\": 1e-08,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"batch_size\": 24,\n","  \"classifier_dropout\": null,\n","  \"device\": \"cuda\",\n","  \"epoch\": 3,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\",\n","    \"9\": \"LABEL_9\",\n","    \"10\": \"LABEL_10\",\n","    \"11\": \"LABEL_11\",\n","    \"12\": \"LABEL_12\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_10\": 10,\n","    \"LABEL_11\": 11,\n","    \"LABEL_12\": 12,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8,\n","    \"LABEL_9\": 9\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"learning_rate\": 0.001,\n","  \"max_grad_norm\": 1.0,\n","  \"max_position_embeddings\": 512,\n","  \"max_seq_len\": 510,\n","  \"model_name\": \"klue/bert-base\",\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"test_data\": \"/content/drive/MyDrive/2_Leture/0_Fast_Campus_NLP/Project_5_NER/klue-ner-v1.1/klue-ner-v1.1_dev.tsv\",\n","  \"train_data\": \"/content/drive/MyDrive/2_Leture/0_Fast_Campus_NLP/Project_5_NER/klue-ner-v1.1/klue-ner-v1.1_train.tsv\",\n","  \"transformers_version\": \"4.25.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 32000\n","}"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["---\n","# 3. train & valid dataset 구성\n","---"],"metadata":{"id":"SnjJd9srV8BX"}},{"cell_type":"code","source":["examples = load_data(init_config.train_data, tokenizer)\n","index = int(len(examples) * 0.1)"],"metadata":{"id":"Dp6tL9i9I3gJ","executionInfo":{"status":"ok","timestamp":1672129878069,"user_tz":-540,"elapsed":3765,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["train_dataset = NerDataset(\n","    tokenizer,\n","    examples[index:]\n",")"],"metadata":{"id":"B8OsKTxHJ7WE","executionInfo":{"status":"ok","timestamp":1672129878070,"user_tz":-540,"elapsed":9,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(\n","    dataset=train_dataset,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    collate_fn=collate_fn\n",")"],"metadata":{"id":"ixlZ9JprKXP1","executionInfo":{"status":"ok","timestamp":1672129878070,"user_tz":-540,"elapsed":8,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["len(train_dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NSpvDX74dQOS","executionInfo":{"status":"ok","timestamp":1672129878070,"user_tz":-540,"elapsed":8,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"ca77babb-dc1b-46a4-d2a8-bf289d7500e7"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1182"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["### Valid dataset"],"metadata":{"id":"QCOjWn1fKfAc"}},{"cell_type":"code","source":["valid_dataset = NerDataset(\n","    tokenizer,\n","    examples[:index]\n",")"],"metadata":{"id":"w-0Zwm86Khzi","executionInfo":{"status":"ok","timestamp":1672129878070,"user_tz":-540,"elapsed":6,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["valid_dataloader = DataLoader(\n","    dataset=valid_dataset,\n","    batch_size=batch_size,\n","    shuffle=False,\n","    collate_fn=collate_fn\n",")"],"metadata":{"id":"XbiL3c3jKkpn","executionInfo":{"status":"ok","timestamp":1672129878071,"user_tz":-540,"elapsed":7,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["---\n","# 4. MODEL\n","----\n","\n","-  Huggingface BertForTokenClassification"],"metadata":{"id":"5BkIaiEIXoxs"}},{"cell_type":"code","source":["model = BertForTokenClassification.from_pretrained(config.model_name, config=config)\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-_sjkEk0Xri-","executionInfo":{"status":"ok","timestamp":1672129882166,"user_tz":-540,"elapsed":4102,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"717c1593-b578-464b-d7b2-ac6c5bc55ef9"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=13, bias=True)\n",")"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["from transformers import AdamW\n","\n","optimizer_grouped_parameters = [\n","    {'params': model.bert.parameters(), 'lr': config.learning_rate / 100 },\n","    {'params': model.classifier.parameters(), 'lr': config.learning_rate }\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=config.learning_rate, eps=config.adam_epsilon)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Gnatq3DX_m1","executionInfo":{"status":"ok","timestamp":1672129882168,"user_tz":-540,"elapsed":59,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"8271f94a-fc0c-4a12-d097-bf0f0aa80ef0"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["---\n","# 5. Train\n","---"],"metadata":{"id":"LqBwnrAHh0Ee"}},{"cell_type":"markdown","source":["- Train_dataloader 살펴보기\n","\n","      input_ids, token_type_ids, attention_mask, input_labels, offset_mappings, char_labels\n","      6개의 값이 넘어옴"],"metadata":{"id":"TDmgt9RAZunz"}},{"cell_type":"code","source":["for batch in train_dataloader:\n","  print(batch)\n","  break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hQOmeq0UZxK-","executionInfo":{"status":"ok","timestamp":1672129882170,"user_tz":-540,"elapsed":57,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"068bcc99-865b-4c4a-dd6d-cfeee1e202a6"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["(tensor([[    2,  1443,  2701,  ...,     0,     0,     0],\n","        [    2, 11699,  2440,  ...,     0,     0,     0],\n","        [    2,  3995, 18045,  ...,     0,     0,     0],\n","        ...,\n","        [    2,  1926,  2978,  ...,     0,     0,     0],\n","        [    2,  7206,  2259,  ...,     0,     0,     0],\n","        [    2,  5686,  1453,  ...,     0,     0,     0]]), tensor([[0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), tensor([[-100,   12,   12,  ..., -100, -100, -100],\n","        [-100,    6,    7,  ..., -100, -100, -100],\n","        [-100,   12,    2,  ..., -100, -100, -100],\n","        ...,\n","        [-100,    0,    1,  ..., -100, -100, -100],\n","        [-100,   12,   12,  ..., -100, -100, -100],\n","        [-100,    4,   12,  ..., -100, -100, -100]]), [[(0, 0), (0, 1), (1, 2), (2, 4), (4, 5), (6, 8), (8, 9), (10, 12), (13, 14), (15, 21), (22, 25), (25, 26), (26, 27), (28, 32), (33, 36), (36, 37), (37, 38), (38, 39), (40, 41), (41, 42), (42, 43), (43, 44), (0, 0)], [(0, 0), (0, 4), (4, 5), (6, 7), (7, 8), (8, 9), (10, 12), (12, 13), (13, 14), (15, 17), (18, 20), (21, 23), (23, 24), (24, 25), (26, 27), (28, 29), (29, 30), (30, 31), (31, 32), (32, 33), (33, 34), (34, 37), (38, 40), (40, 41), (41, 42), (42, 43), (0, 0)], [(0, 0), (0, 2), (3, 7), (7, 9), (9, 10), (11, 14), (14, 16), (17, 18), (18, 19), (19, 20), (21, 22), (23, 26), (27, 29), (30, 32), (32, 33), (34, 35), (35, 36), (37, 39), (39, 40), (40, 41), (42, 45), (46, 48), (49, 51), (51, 52), (53, 56), (56, 57), (57, 58), (58, 59), (0, 0)], [(0, 0), (0, 2), (3, 5), (5, 6), (7, 11), (11, 12), (12, 16), (16, 17), (17, 18), (19, 21), (22, 24), (24, 25), (26, 27), (27, 28), (29, 31), (32, 34), (34, 36), (37, 39), (39, 40), (41, 43), (43, 44), (45, 48), (48, 49), (50, 52), (53, 58), (58, 60), (60, 61), (62, 63), (64, 66), (66, 67), (68, 70), (70, 71), (72, 73), (74, 75), (75, 76), (76, 77), (78, 80), (80, 81), (81, 82), (82, 83), (0, 0)], [(0, 0), (0, 1), (1, 2), (3, 5), (5, 7), (7, 11), (11, 12), (13, 15), (15, 16), (17, 18), (18, 21), (22, 23), (24, 27), (27, 28), (28, 29), (30, 32), (32, 33), (33, 34), (34, 36), (36, 37), (37, 38), (38, 39), (40, 42), (43, 44), (44, 45), (46, 48), (49, 51), (51, 53), (54, 55), (55, 56), (56, 57), (58, 60), (61, 64), (64, 66), (67, 69), (69, 71), (71, 72), (73, 75), (75, 76), (77, 78), (79, 82), (83, 84), (84, 85), (86, 88), (88, 89), (90, 91), (91, 92), (92, 94), (94, 95), (96, 99), (100, 101), (101, 102), (102, 104), (105, 106), (106, 108), (108, 109), (110, 112), (112, 113), (114, 116), (117, 119), (119, 120), (120, 121), (121, 122), (0, 0)], [(0, 0), (0, 1), (1, 2), (3, 4), (4, 5), (6, 8), (8, 9), (9, 11), (12, 13), (14, 15), (15, 16), (16, 17), (18, 20), (20, 21), (22, 24), (24, 25), (26, 29), (30, 31), (31, 32), (32, 34), (34, 35), (35, 36), (36, 37), (37, 38), (39, 43), (44, 45), (45, 47), (47, 48), (49, 50), (50, 51), (51, 52), (0, 0)], [(0, 0), (0, 1), (1, 2), (2, 3), (4, 5), (6, 8), (9, 11), (11, 13), (14, 15), (15, 16), (17, 19), (20, 22), (22, 23), (23, 25), (25, 26), (0, 0)], [(0, 0), (0, 1), (1, 2), (3, 6), (7, 8), (8, 9), (9, 10), (11, 14), (14, 15), (15, 16), (16, 17), (17, 19), (19, 20), (20, 21), (21, 22), (22, 23), (24, 26), (26, 28), (29, 31), (31, 32), (33, 35), (35, 36), (37, 39), (39, 40), (0, 0)], [(0, 0), (0, 2), (3, 5), (5, 6), (6, 7), (7, 8), (9, 12), (13, 15), (15, 16), (16, 17), (17, 18), (18, 20), (0, 0)], [(0, 0), (0, 2), (2, 3), (3, 4), (5, 6), (7, 8), (8, 9), (10, 12), (12, 13), (14, 16), (16, 18), (18, 19), (19, 20), (20, 21), (21, 22), (22, 23), (23, 24), (0, 0)], [(0, 0), (0, 1), (1, 2), (2, 3), (4, 6), (7, 10), (11, 13), (13, 14), (14, 15), (15, 16), (17, 18), (19, 20), (20, 21), (22, 23), (0, 0)], [(0, 0), (0, 1), (1, 2), (3, 5), (5, 6), (7, 10), (11, 13), (13, 14), (14, 15), (16, 17), (17, 18), (18, 20), (21, 22), (22, 24), (24, 25), (26, 28), (29, 31), (31, 32), (32, 33), (33, 34), (0, 0)], [(0, 0), (0, 1), (2, 4), (4, 6), (7, 9), (10, 11), (12, 14), (14, 15), (15, 16), (17, 20), (20, 22), (23, 24), (24, 25), (25, 26), (26, 27), (27, 28), (29, 31), (31, 32), (33, 35), (36, 38), (38, 40), (40, 41), (41, 42), (42, 43), (43, 44), (0, 0)], [(0, 0), (0, 1), (1, 2), (2, 3), (4, 6), (6, 7), (7, 8), (8, 9), (10, 11), (11, 12), (13, 15), (16, 18), (18, 19), (19, 20), (21, 22), (22, 23), (23, 24), (24, 25), (25, 26), (27, 28), (28, 29), (29, 30), (30, 31), (31, 32), (33, 35), (35, 36), (36, 39), (39, 40), (0, 0)], [(0, 0), (0, 2), (2, 3), (4, 5), (5, 6), (6, 7), (8, 13), (13, 14), (15, 16), (16, 18), (18, 19), (20, 22), (22, 23), (24, 26), (27, 28), (28, 30), (30, 31), (32, 35), (35, 37), (37, 38), (38, 39), (40, 43), (43, 44), (0, 0)], [(0, 0), (0, 2), (3, 4), (4, 5), (5, 6), (7, 9), (10, 13), (13, 14), (15, 17), (17, 18), (19, 21), (21, 23), (23, 24), (0, 0)]], [['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-DT', 'I-DT', 'I-DT', 'I-DT', 'I-DT', 'O', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'B-LC', 'I-LC', 'I-LC', 'I-LC', 'O', 'O', 'O', 'O', 'B-DT', 'I-DT', 'I-DT', 'O', 'O', 'O', 'B-LC', 'I-LC', 'I-LC', 'I-LC', 'I-LC', 'I-LC', 'I-LC', 'I-LC', 'I-LC', 'I-LC', 'I-LC', 'I-LC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-OG', 'I-OG', 'O', 'O', 'O', 'O', 'O', 'B-DT', 'I-DT', 'I-DT', 'I-DT', 'I-DT', 'I-DT', 'I-DT', 'I-DT', 'I-DT', 'I-DT', 'I-DT', 'O', 'O', 'O', 'O', 'B-DT', 'I-DT', 'I-DT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OG', 'I-OG', 'I-OG', 'O', 'O', 'B-DT', 'I-DT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-DT', 'I-DT', 'O', 'B-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'I-OG', 'O', 'O', 'O', 'B-DT', 'I-DT', 'I-DT', 'I-DT', 'I-DT', 'O', 'B-TI', 'I-TI', 'O', 'B-LC', 'I-LC', 'I-LC', 'I-LC', 'I-LC', 'I-LC', 'I-LC', 'I-LC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'I-QT', 'I-QT', 'I-QT', 'I-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LC', 'I-LC', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'B-DT', 'I-DT', 'I-DT', 'I-DT', 'I-DT', 'I-DT', 'I-DT', 'O', 'O', 'O', 'O', 'O', 'B-QT', 'I-QT', 'I-QT', 'I-QT', 'I-QT', 'I-QT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'B-DT', 'I-DT', 'I-DT', 'I-DT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'I-PS', 'I-PS', 'I-PS', 'I-PS', 'I-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'B-PS', 'I-PS', 'I-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-PS', 'I-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['B-OG', 'I-OG', 'O', 'O', 'O', 'O', 'O', 'B-DT', 'I-DT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']])\n"]}]},{"cell_type":"code","source":["def train_epoch(model, dataloader, optimizer):\n","  model.train()\n","  total_loss = 0.0\n","  echo_loss = 0.0\n","\n","  # input_ids, token_type_ids, attention_mask, input_labels, offset_mappings, char_labels\n","  for batch in tqdm(dataloader):\n","    inputs = {\n","        'input_ids' : batch[0].to(config.device),\n","        'token_type_ids' : batch[1].to(config.device),\n","        'attention_mask' : batch[2].to(config.device),\n","        'labels' : batch[3].to(config.device),\n","    }\n","    outputs = model(**inputs) # 사전 형식으로 넣기 \n","    loss = outputs[0]\n","    loss.backward()\n","    optimizer.step()\n","    total_loss += loss\n","\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n","\n","  return total_loss.mean()"],"metadata":{"id":"nFUYwoBiZxeR","executionInfo":{"status":"ok","timestamp":1672129882172,"user_tz":-540,"elapsed":51,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["for epoch in range(config.epoch):\n","    # Train\n","    train_loss = train_epoch(model, train_dataloader, optimizer)\n","    print(f\"{epoch}: {train_loss}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":167,"referenced_widgets":["e15b8d4b822844cd9027f34f1bd13685","d47844ca1ea64debb1ec38922d08aef6","d995e99aff2b44b29ac5229b5b5a8480","a36ed2eff933434cbc92bc61713bd2e1","fa838b54de6143589a067d4c7d40a048","c752ccb53a364a9b982834e5c07f2fa0","8c532c15d92c44c7840925a686daf343","a82328d869b94ccf94e8960747751d93","123a49a25f8146a085e73b4fcc1e0fe8","f3001ab50edd4d90ab707777dbfd905b","e1aee2d3a670420fbfbc7cf3c77a9359","29ff09eb5464495994a5920d38b82e9a","f90ecc806dc9447cbc9b6d7ada9da68f","f0e2deebb5344db38ce86c6f12e8fbe3","8d0d935b1f0a4937aa4085268e0f3fd5","d2914c0bf93d4572b69491af9360956f","29503f4d74b74f0d931755a685f69178","d9b50ae13c0a49c0905b1a7bcc2b8cd7","ef0a0d829e854de09e3d1a4b5f61dad6","0590b64900174e85a25c1c897f8fcfb3","448073dccc7e4c298e3773f072c664ee","eef78d65df8e4d7a86ce0926187d8a16","ed6f697a45e2480b996e38c3dd46ffa5","84666c37b9ca4f07ba5b2f08e1208578","3d98ad32232a4906801e5e275fa1f570","f1e1997ecbfa47f2822cfe68e202b1ab","6e658c98ca1d4201a875b1cad76e1805","385ba1c8ce3545dd86e2cf98cc7114b1","dc30446905534e9bb15e9a1978c62e88","0cd9783f1b83414b996098fc8c60809f","286c74f8fa1c45e990e35a4c7a9ef1f3","45558df81e274741bda1f77ef36d4d21","577c3d329c884c7b92b7f3bf4f53313e"]},"id":"FHHOGJU-dCDx","executionInfo":{"status":"ok","timestamp":1672131147607,"user_tz":-540,"elapsed":1265485,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"34a8aa25-cefd-4264-c31f-af595cfd84be"},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1182 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e15b8d4b822844cd9027f34f1bd13685"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["0: 131.19424438476562\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1182 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29ff09eb5464495994a5920d38b82e9a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["1: 65.23534393310547\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1182 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed6f697a45e2480b996e38c3dd46ffa5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["2: 45.42474365234375\n"]}]},{"cell_type":"markdown","source":["---\n","# 6. 평가 Matrix\n","---"],"metadata":{"id":"E5ukYgKrgtx3"}},{"cell_type":"markdown","source":["### Token level Evaluation\n","- precision, recall\n","- F1-score"],"metadata":{"id":"V5MZ1Bd5rO3E"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=16SpB14dAfmPV7bP-QL6T44wIUFy5RoAy\" width=\"500\"/>"],"metadata":{"id":"NOgqGbPxXjKU"}},{"cell_type":"markdown","source":["\n","<img src=\"https://drive.google.com/uc?id=1joFpdIY84JgNv-hEVBu-Ud1YGp9EzoY3\" width=\"500\"/>"],"metadata":{"id":"y8R9uyh8YFo9"}},{"cell_type":"markdown","source":["### seqeval"],"metadata":{"id":"qy_Qe9H6lyjS"}},{"cell_type":"code","source":["!pip -q install seqeval"],"metadata":{"id":"u_YTCtfMY6gi","executionInfo":{"status":"ok","timestamp":1672131151315,"user_tz":-540,"elapsed":3199,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["from seqeval.metrics import accuracy_score, performance_measure\n","from seqeval.metrics import classification_report\n","from seqeval.metrics import f1_score\n"],"metadata":{"id":"IFL9EOaGZk7i","executionInfo":{"status":"ok","timestamp":1672131151316,"user_tz":-540,"elapsed":25,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":["---\n","### 6-1. 예시\n","---\n","\n"],"metadata":{"id":"jymeOP0WhACG"}},{"cell_type":"code","source":["y_true = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O']]\n","y_pred = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O']]\n","print(classification_report(y_true, y_pred))"],"metadata":{"id":"cR8a3-13Y927","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672131151316,"user_tz":-540,"elapsed":24,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"401cad4d-b5c2-41b1-99e4-a595ad7092f6"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","        MISC       0.00      0.00      0.00         1\n","\n","   micro avg       0.00      0.00      0.00         1\n","   macro avg       0.00      0.00      0.00         1\n","weighted avg       0.00      0.00      0.00         1\n","\n"]}]},{"cell_type":"code","source":["y_true = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n","y_pred = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n","\n","print(classification_report(y_true, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JBeNvv3tb7I0","executionInfo":{"status":"ok","timestamp":1672131151317,"user_tz":-540,"elapsed":24,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"0af0c7f2-4f03-4510-e149-170b239a4c8e"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","        MISC       0.00      0.00      0.00         1\n","         PER       1.00      1.00      1.00         1\n","\n","   micro avg       0.50      0.50      0.50         2\n","   macro avg       0.50      0.50      0.50         2\n","weighted avg       0.50      0.50      0.50         2\n","\n"]}]},{"cell_type":"code","source":["y_true = [['B-PER', 'I-PER', 'O']]\n","y_pred = [['B-LOC', 'I-LOC', 'O']]\n","\n","print(classification_report(y_true, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wU8rAhXbcEUn","executionInfo":{"status":"ok","timestamp":1672131151317,"user_tz":-540,"elapsed":22,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"8a512a6e-a00e-4c74-eeab-8f2ca0ffa7ca"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         LOC       0.00      0.00      0.00         0\n","         PER       0.00      0.00      0.00         1\n","\n","   micro avg       0.00      0.00      0.00         1\n","   macro avg       0.00      0.00      0.00         1\n","weighted avg       0.00      0.00      0.00         1\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.8/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["y_true = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'B-PER', 'O'], ['B-MISC', 'I-MISC', 'O']]\n","y_pred = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O', 'O'], ['B-MISC', 'I-MISC', 'O']]\n","\n","print(classification_report(y_true, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zrPx4UC-af2K","executionInfo":{"status":"ok","timestamp":1672131151317,"user_tz":-540,"elapsed":20,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"3621998c-cae1-49d8-98ef-d082f83aa00d"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","        MISC       1.00      1.00      1.00         2\n","         PER       0.00      0.00      0.00         1\n","\n","   micro avg       1.00      0.67      0.80         3\n","   macro avg       0.50      0.50      0.50         3\n","weighted avg       0.67      0.67      0.67         3\n","\n"]}]},{"cell_type":"markdown","source":["---\n","# 7. Validation\n","---"],"metadata":{"id":"EBm7jgRZh5DB"}},{"cell_type":"code","source":["def valid_epoch(dataloader, model):\n","    total_loss = 0.0\n","\n","    model.eval()\n","    all_token_predictions = []\n","    all_token_labels = []\n","    for i, batch in enumerate(tqdm(dataloader)):\n","        with torch.no_grad():\n","            input_ids = batch[0].to(config.device)\n","            token_type_ids = batch[1].to(config.device)\n","            attention_mask = batch[2].to(config.device)\n","            labels = batch[3].to(config.device)\n","\n","            inputs = {\n","                \"input_ids\": input_ids,\n","                \"attention_mask\": attention_mask,\n","                \"token_type_ids\": token_type_ids,\n","                \"labels\": labels\n","            }\n","\n","            outputs = model(**inputs) # loss / logits / hidden_state / attenions\n","            loss, logits = outputs[:2]\n","            total_loss += loss.item()\n","            \n","            ###### predict ######\n","            token_predictions = logits.argmax(dim=2) # logits\n","            token_predictions = token_predictions.detach().cpu().numpy()\n","            \n","            for token_prediction, label in zip(token_predictions, labels):\n","                filtered = []\n","                filtered_label = []\n","                for i in range(len(token_prediction)):\n","                    if label[i].tolist() == -100:\n","                        continue\n","                    filtered.append(id2label[token_prediction[i]])\n","                    filtered_label.append(id2label[label[i].tolist()])\n","                assert len(filtered) == len(filtered_label)\n","                all_token_predictions.append(filtered)\n","                all_token_labels.append(filtered_label)\n","    \n","    token_f1 = f1_score(all_token_labels, all_token_predictions, average=\"macro\")\n","    return total_loss / len(dataloader),  token_f1, all_token_labels, all_token_predictions"],"metadata":{"id":"Zomt43KgjLAS","executionInfo":{"status":"ok","timestamp":1672131151317,"user_tz":-540,"elapsed":17,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["for epoch in range(config.epoch):\n","    # validation\n","    valid_loss, valid_f1, all_token_labels, all_token_predictions = valid_epoch(valid_dataloader, model)\n","    print(f\"\\n{epoch+1}/{config.epoch} valid loss: {train_loss} valid_f1: {valid_f1}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85,"referenced_widgets":["eeff79342c1540e89dcb7eb41f018ed5","148559b6b51047a39c7794d21d4d2596","63d5a84821b6407591c988f3cf1645b3","3be2f8c59fd3495e9fc987f02355d6be","1e4d5f5935ca4e2fb74becaf42184daf","8daa72aa98af4f59a982f7d5d68c199d","ea7ed472d1d64325bbf5d0ee64946576","6d000ae64431469b984f8eacf544dea4","ed15440bd8a642f08037db4f11be4271","c77279ab353849a6bfd0d95012dccddb","171b58daaec64825bf2ee6d02135dd53"]},"id":"wt1LajQAh_jJ","executionInfo":{"status":"ok","timestamp":1672131171877,"user_tz":-540,"elapsed":20577,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"ddb6194e-584f-4cf3-fc89-9388700370b7"},"execution_count":53,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/132 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eeff79342c1540e89dcb7eb41f018ed5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","1/3 valid loss: 45.42474365234375 valid_f1: 0.8749796836396273\n"]}]},{"cell_type":"markdown","source":["- 잘 담겨있는지 첫 번째로 확인"],"metadata":{"id":"JS67bxBBj40w"}},{"cell_type":"code","source":["for label, pred in zip(all_token_labels[0], all_token_predictions[0]):\n","    print(f\"{label}\\t{pred}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BctSDsJEjvgF","executionInfo":{"status":"ok","timestamp":1672131171878,"user_tz":-540,"elapsed":35,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"3c7589b3-6449-4d31-91bf-9d81c1e22366"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["O\tO\n","B-LC\tB-LC\n","B-LC\tB-LC\n","O\tO\n","B-LC\tB-LC\n","I-LC\tI-LC\n","I-LC\tI-LC\n","I-LC\tI-LC\n","I-LC\tI-LC\n","O\tO\n","B-LC\tB-LC\n","I-LC\tI-LC\n","I-LC\tI-LC\n","I-LC\tI-LC\n","I-LC\tI-LC\n","O\tO\n","O\tO\n","B-QT\tB-QT\n","I-QT\tI-QT\n","I-QT\tI-QT\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n","O\tO\n"]}]},{"cell_type":"markdown","source":["---\n","### 7-1. Character level Evaluation\n","----"],"metadata":{"id":"VJpucjtWkJ2s"}},{"cell_type":"markdown","source":["![이미지](https://drive.google.com/uc?id=1SJqXt_OZXQofigSMgJO-w1sor9uaiI77)"],"metadata":{"id":"mswdk-TckfCo"}},{"cell_type":"markdown","source":["![이미지](https://drive.google.com/uc?id=19O7DGe7-cD-F8MT3O9Syn4t9GlxAQoYz)"],"metadata":{"id":"QKhHQfD-lTvL"}},{"cell_type":"code","source":["text = \"7일 고양에서 열린 친선경기에서 손흥민은\"\n","offset_mappings = tokenizer(text, return_offsets_mapping=True)[\"offset_mapping\"]\n","offset_mappings"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y6jLRbb6lWwy","executionInfo":{"status":"ok","timestamp":1672131171878,"user_tz":-540,"elapsed":32,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"572cd81e-c701-4f73-a9d1-6479f152d405"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, 0),\n"," (0, 1),\n"," (1, 2),\n"," (3, 5),\n"," (5, 7),\n"," (8, 10),\n"," (11, 13),\n"," (13, 15),\n"," (15, 17),\n"," (18, 21),\n"," (21, 22),\n"," (0, 0)]"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["tokenized = tokenizer.tokenize(text)"],"metadata":{"id":"1Qn9NaOKlnjO","executionInfo":{"status":"ok","timestamp":1672131171878,"user_tz":-540,"elapsed":30,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":["- 토큰의 길이와 오프셋의 길이가 동일"],"metadata":{"id":"mbdVbwAVl_tc"}},{"cell_type":"code","source":["for token, offset in zip(tokenized, offset_mappings[1:]):\n","    start, end = offset\n","    print(f\"{token}\\t{offset}\\t{end-start}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qaHLvTWOl4gy","executionInfo":{"status":"ok","timestamp":1672131171878,"user_tz":-540,"elapsed":30,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"347e5646-ba41-4345-88e4-96c0bbf77252"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["7\t(0, 1)\t1\n","##일\t(1, 2)\t1\n","고양\t(3, 5)\t2\n","##에서\t(5, 7)\t2\n","열린\t(8, 10)\t2\n","친선\t(11, 13)\t2\n","##경기\t(13, 15)\t2\n","##에서\t(15, 17)\t2\n","손흥민\t(18, 21)\t3\n","##은\t(21, 22)\t1\n"]}]},{"cell_type":"code","source":["labels = [\"B-DT\", \"I-DT\", \"B-LC\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PS\", \"O\"]\n","\n","for token, offset, label in zip(tokenized, offset_mappings[1:], labels):\n","    start, end = offset\n","    print(f\"{token}\\t{offset}\\t{end-start}\\t{label}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PqVa8Pncl_jw","executionInfo":{"status":"ok","timestamp":1672131171879,"user_tz":-540,"elapsed":28,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"3a5567bd-7709-4aad-85a2-84e7840c57ef"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["7\t(0, 1)\t1\tB-DT\n","##일\t(1, 2)\t1\tI-DT\n","고양\t(3, 5)\t2\tB-LC\n","##에서\t(5, 7)\t2\tO\n","열린\t(8, 10)\t2\tO\n","친선\t(11, 13)\t2\tO\n","##경기\t(13, 15)\t2\tO\n","##에서\t(15, 17)\t2\tO\n","손흥민\t(18, 21)\t3\tB-PS\n","##은\t(21, 22)\t1\tO\n"]}]},{"cell_type":"code","source":["# token level label을 char level label로 변경\n","def token_to_char_label(token_predicts, offset_mappings):\n","\n","    char_prediction = []\n","    \n","    prev_end = None\n","    for token_predict, offset_mapping in zip(token_predicts, offset_mappings[1:]):\n","        start, end = offset_mapping\n","\n","        # 이전 end와 현재 start가 1개이상 차이나면 띄어쓰기를 추가한다\n","        if prev_end != None and start - prev_end > 0:\n","            char_prediction.append(\"O\") # 띄어쓰기\n","        prev_end = end\n","\n","        # 싱글 라벨\n","        if end - start == 1: # 토큰이 하나 차이가 나면 \n","            char_prediction.append(token_predict) # 토큰 하나를 더해줌\n","            continue\n","        \n","        # 멀티 라벨\n","        for i in range(end - start): # 2개 이상 차이가 나면\n","            if i == 0 or token_predict == \"O\":\n","                char_prediction.append(token_predict)\n","                continue\n","            char_prediction.append(\"I-\" + token_predict.split(\"-\")[1]) # b-lc를 i-lc로 바꾸는 코드 \n","\n","    return char_prediction"],"metadata":{"id":"J-14tmhUmTKJ","executionInfo":{"status":"ok","timestamp":1672131171879,"user_tz":-540,"elapsed":26,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["predicts = [\"B-DT\", \"I-DT\", \"B-LC\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PS\", \"O\"]\n","\n","char = token_to_char_label(predicts, offset_mappings)\n","print(char)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PpdILRoBnE2T","executionInfo":{"status":"ok","timestamp":1672131171879,"user_tz":-540,"elapsed":25,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"82050ef1-29c0-4f37-c4c8-1a8f4b7b6cc3"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["['B-DT', 'I-DT', 'O', 'B-LC', 'I-LC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PS', 'I-PS', 'I-PS', 'O']\n"]}]},{"cell_type":"code","source":["for t, c in zip(text, char):\n","    print(f\"{t}\\t{c}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_oRG4jxLndQR","executionInfo":{"status":"ok","timestamp":1672131171879,"user_tz":-540,"elapsed":23,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"e3ef5c48-5237-4642-80b6-5822dd30304b"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["7\tB-DT\n","일\tI-DT\n"," \tO\n","고\tB-LC\n","양\tI-LC\n","에\tO\n","서\tO\n"," \tO\n","열\tO\n","린\tO\n"," \tO\n","친\tO\n","선\tO\n","경\tO\n","기\tO\n","에\tO\n","서\tO\n"," \tO\n","손\tB-PS\n","흥\tI-PS\n","민\tI-PS\n","은\tO\n"]}]},{"cell_type":"code","source":["# token level label을 char level label로 변경 \n","def token_to_char_label(token_predictions, labels, offset_mapping_batch):\n","    char_predictions = []\n","    for token_predicts, label, offset_mappings in zip(token_predictions, labels, offset_mapping_batch):\n","\n","        # SPECIAL token 제외\n","        filtered = []\n","        for i in range(len(token_predicts)):\n","            if label[i].tolist() == -100:\n","                continue\n","            filtered.append(token_predicts[i])\n","        char_prediction = []\n","\n","        # SPECIAL token 제외\n","        if offset_mappings[0][0] == 0 and offset_mappings[0][1] == 0:\n","            del offset_mappings[0]\n","        if offset_mappings[-1][0] == 0 and offset_mappings[-1][1] == 0:\n","            del offset_mappings[-1]\n","        assert len(filtered) == len(offset_mappings)\n","\n","        prev_end = None\n","        for token_predict, offset_mapping in zip(filtered, offset_mappings):\n","            start, end = offset_mapping\n","\n","            # 이전 end와 현재 start가 1개이상 차이나면 띄어쓰기를 추가한다\n","            if prev_end != None and start - prev_end > 0:\n","                char_prediction.append(\"O\") # 띄어쓰기\n","            prev_end = end\n","\n","            # 싱글 라벨\n","            if end - start == 1: # 토큰이 하나 차이가 나면 \n","                label_str = id2label[token_predict] # 토큰 하나를 더해줌\n","                char_prediction.append(label_str)\n","                continue\n","            \n","            # 멀티 라벨\n","            for i in range(end - start): # 2개 이상 차이가 나면\n","                label_str = id2label[token_predict]\n","                if i == 0 or label_str == \"O\":\n","                    char_prediction.append(label_str)\n","                    continue\n","                char_prediction.append(\"I-\" + label_str.split(\"-\")[1]) # b-lc를 i-lc로 바꾸는 코드 \n","        char_predictions.append(char_prediction)\n","    return char_predictions"],"metadata":{"id":"3-GXh_SpmYpN","executionInfo":{"status":"ok","timestamp":1672131171880,"user_tz":-540,"elapsed":22,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":["---\n","# 8. Test\n","----"],"metadata":{"id":"EcSHJL0Gne95"}},{"cell_type":"code","source":["def test_epoch(dataloader, model, tokenizer):\n","    total_loss = 0.0\n","\n","    model.eval()\n","    all_char_preds = []\n","    all_char_labels = []\n","    all_token_predictions = []\n","    all_token_labels = []\n","    for i, batch in enumerate(tqdm(dataloader)):\n","        with torch.no_grad():\n","            labels = batch[3].to(config.device)\n","            offset_mappings = batch[4]\n","            char_labels = batch[5]\n","            inputs = {\n","                \"input_ids\": batch[0].to(config.device),\n","                \"attention_mask\": batch[2].to(config.device),\n","                \"token_type_ids\": batch[1].to(config.device),\n","                \"labels\": labels,\n","            }\n","\n","            outputs = model(**inputs)\n","\n","            loss, logits = outputs[:2]\n","            total_loss += loss.item()\n","\n","            token_predictions = logits.argmax(dim=2) # logits\n","            token_predictions = token_predictions.detach().cpu().numpy()\n","\n","            ################### Chracter Level Evaluation ###################\n","            char_predictions = token_to_char_label(token_predictions, labels, offset_mappings) # token을 char로 변환\n","            for j, (char_pred, char_label) in enumerate(zip(char_predictions, char_labels)):\n","                if len(char_pred) != len(char_label):\n","                    print(tokenizer.decode(batch[0][j]))\n","                    del char_predictions[j]\n","                    del char_labels[j]\n","\n","            all_char_preds.extend(char_predictions)\n","            all_char_labels.extend(char_labels)\n","            #################################################################\n","\n","            ##################### Token Level Evaluation ####################\n","            for token_prediction, label in zip(token_predictions, labels):\n","                filtered = []\n","                filtered_label = []\n","                for i in range(len(token_prediction)):\n","                    if label[i].tolist() == -100:\n","                        continue\n","                    filtered.append(id2label[token_prediction[i]])\n","                    filtered_label.append(id2label[label[i].tolist()])\n","                assert len(filtered) == len(filtered_label)\n","                all_token_predictions.append(filtered)\n","                all_token_labels.append(filtered_label)\n","            #################################################################\n","    token_result = classification_report(all_token_labels, all_token_predictions)\n","    token_f1 = f1_score(all_token_labels, all_token_predictions, average=\"macro\")\n","    print(token_result)\n","\n","    char_result = classification_report(all_char_labels, all_char_preds)\n","    print(char_result)\n","    char_f1 = f1_score(all_char_labels, all_char_preds)\n","    return total_loss / len(dataloader), token_f1, char_f1"],"metadata":{"id":"4r2WY8ZRngay","executionInfo":{"status":"ok","timestamp":1672131171880,"user_tz":-540,"elapsed":22,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["examples = load_data(init_config.test_data, tokenizer)"],"metadata":{"id":"7O3s2fQ0qL0E","executionInfo":{"status":"ok","timestamp":1672131173308,"user_tz":-540,"elapsed":1449,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["test_dataset = NerDataset(\n","    tokenizer,\n","    examples,\n",")"],"metadata":{"id":"2a38OaKIqNaG","executionInfo":{"status":"ok","timestamp":1672131173309,"user_tz":-540,"elapsed":18,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["test_dataloader = DataLoader(\n","    dataset=valid_dataset,\n","    batch_size=batch_size,\n","    shuffle=False,\n","    collate_fn=collate_fn\n",")"],"metadata":{"id":"VD1-uK--qV7e","executionInfo":{"status":"ok","timestamp":1672131173310,"user_tz":-540,"elapsed":18,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["for epoch in range(config.epoch):\n","    # Test\n","    test_loss, token_f1, char_f1 = test_epoch(test_dataloader, model, tokenizer)\n","    print(f\"\\n{epoch+1}/{config.epoch} test loss: {test_loss} token_f1: {token_f1} char_f1: {char_f1}\")\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":591,"referenced_widgets":["091abda4322d480a98f2168ed0b31fab","092cac22d81640b992dca5b14407a14a","8fc97432f1924fc282020bef9118dd99","cb6a1b885cec4c85871c0e1f8c354009","e6f5094e2e2b4345ba7a5f27954227fe","2ec729c738f54575b4327c25baae7291","0a3f601de387477ea89bbc1504509be5","6bc65a3d12bf46e786f04d038fb8b2a5","817b4a2afd0143c19e48b781004d2796","f75ab65d1c46404a9bd2f36a7d1345ed","3214491d271f4c2d93d83a64d4599d76"]},"id":"A3t7wjpBoOaK","executionInfo":{"status":"ok","timestamp":1672131200315,"user_tz":-540,"elapsed":27022,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"01745d74-e237-4b3e-a588-866a6e1dfca4"},"execution_count":67,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/132 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"091abda4322d480a98f2168ed0b31fab"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[CLS] 벤허 역은 말론 브란도도 탐냈던 배역인데 190cm의 찰톤 헤스톤 보다 175cm의 차돌 같은 말론 브란도가 더 어울렸을 듯! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","              precision    recall  f1-score   support\n","\n","          DT       0.81      0.87      0.84       793\n","          LC       0.80      0.84      0.82       648\n","          OG       0.78      0.85      0.81       797\n","          PS       0.92      0.94      0.93      1357\n","          QT       0.90      0.95      0.92      1235\n","          TI       0.93      0.93      0.93       220\n","\n","   micro avg       0.86      0.90      0.88      5050\n","   macro avg       0.86      0.89      0.87      5050\n","weighted avg       0.86      0.90      0.88      5050\n","\n","              precision    recall  f1-score   support\n","\n","          DT       0.56      0.76      0.64       793\n","          LC       0.58      0.75      0.66       649\n","          OG       0.62      0.75      0.68       809\n","          PS       0.71      0.83      0.77      1355\n","          QT       0.73      0.85      0.79      1237\n","          TI       0.43      0.62      0.51       221\n","\n","   micro avg       0.64      0.79      0.71      5064\n","   macro avg       0.61      0.76      0.67      5064\n","weighted avg       0.65      0.79      0.71      5064\n","\n","\n","1/3 test loss: 0.08335346924705488 token_f1: 0.8749796836396273 char_f1: 0.7097576134244873\n"]}]}]}