{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "14b2e875277144408546d3b95631f3cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62f095cd98ef4bbdb68824183ea45b3c",
              "IPY_MODEL_7527bb7e252941ccab46184edf529404",
              "IPY_MODEL_c186d806be054d7ca8edcc4464d6d49e"
            ],
            "layout": "IPY_MODEL_f8d34da8270d453aa6031c3309e33720"
          }
        },
        "62f095cd98ef4bbdb68824183ea45b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc4a7511266a4b5cac62ac691282ffe3",
            "placeholder": "​",
            "style": "IPY_MODEL_8c4139e039124d26af51814cd25887c3",
            "value": "100%"
          }
        },
        "7527bb7e252941ccab46184edf529404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20a0b4799e334706820103d2dc8f9224",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5617fd0617764c0b96f5efeedb4199f1",
            "value": 100
          }
        },
        "c186d806be054d7ca8edcc4464d6d49e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_210d86e55bae43e4898e773d8e2506b3",
            "placeholder": "​",
            "style": "IPY_MODEL_08e661d603604a6cac33f4222697ee98",
            "value": " 100/100 [00:03&lt;00:00, 32.52it/s]"
          }
        },
        "f8d34da8270d453aa6031c3309e33720": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc4a7511266a4b5cac62ac691282ffe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c4139e039124d26af51814cd25887c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20a0b4799e334706820103d2dc8f9224": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5617fd0617764c0b96f5efeedb4199f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "210d86e55bae43e4898e773d8e2506b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08e661d603604a6cac33f4222697ee98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# CBOW\n",
        "---"
      ],
      "metadata": {
        "id": "F_cWtnnGSvmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## using pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm.notebook import tqdm\n",
        "EMBEDDING_DIM = 128\n",
        "EPOCHS = 100\n",
        "\n",
        "sentence = '''In the case of CBOW, one word is eliminated, and the word is predicted from surrounding words.\n",
        "Therefore, it takes multiple input vectors as inputs to the model and creates one output vector.\n",
        "In contrast, Skip-Gram learns by removing all words except one word and predicting the surrounding words in the context through one word. \n",
        "So, it takes a vector as input and produces multiple output vectors.\n",
        "CBOW and Skip-Gram are different.'''\n",
        "\n",
        "ex_sample = sentence.split()\n",
        "print(ex_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eThgc4wSw6u",
        "outputId": "a538a021-ae6c-45f5-da5f-53c81a031803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['In', 'the', 'case', 'of', 'CBOW,', 'one', 'word', 'is', 'eliminated,', 'and', 'the', 'word', 'is', 'predicted', 'from', 'surrounding', 'words.', 'Therefore,', 'it', 'takes', 'multiple', 'input', 'vectors', 'as', 'inputs', 'to', 'the', 'model', 'and', 'creates', 'one', 'output', 'vector.', 'In', 'contrast,', 'Skip-Gram', 'learns', 'by', 'removing', 'all', 'words', 'except', 'one', 'word', 'and', 'predicting', 'the', 'surrounding', 'words', 'in', 'the', 'context', 'through', 'one', 'word.', 'So,', 'it', 'takes', 'a', 'vector', 'as', 'input', 'and', 'produces', 'multiple', 'output', 'vectors.', 'CBOW', 'and', 'Skip-Gram', 'are', 'different.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###### 입력받은 문장을 단어로 쪼개고, 중복을 제거해줍니다. ######\n",
        "\n",
        "vocab = set(ex_sample) # 중복 제거\n",
        "vocab_size = len(ex_sample)\n",
        "\n",
        "###### 단어 : 인덱스, 인덱스 : 단어를 가지는 딕셔너리를 선언해 줍니다. ######\n",
        "\n",
        "word_to_idx = {word : index for index, word in enumerate(vocab)}\n",
        "idx_to_word = {index : word for index, word in enumerate(vocab)}\n",
        "\n",
        "print(len(word_to_idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa9trWVuTeJw",
        "outputId": "403f63a3-2da3-43b3-f442-5a1837617930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### 학습을 위한 데이터를 생성 #####\n",
        "\n",
        "def make_context_vector(context, word_to_idx):\n",
        "  idxs = [word_to_idx[i] for i in context]\n",
        "  return torch.tensor(idxs , dtype = torch.long)\n",
        "\n",
        "def make_data(sentence):\n",
        "  data = []\n",
        "  for i in range(2, len(ex_sample)-2):\n",
        "    context = [ex_sample[i-2], ex_sample[i-1], ex_sample[i+1], ex_sample[i+2]]\n",
        "    target = ex_sample[i]\n",
        "    data.append((context, target))\n",
        "  return data\n",
        "\n",
        "data = make_data(ex_sample)"
      ],
      "metadata": {
        "id": "_7tmZS9fUqgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### CBOW Model #####\n",
        "\n",
        "class CBOW(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(CBOW, self).__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.layer1 = nn.Linear(embedding_dim,64)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.layer2 = nn.Linear(64,vocab_size)\n",
        "    self.softmax = nn.LogSoftmax(dim = -1)\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    out = sum(self.embedding(inputs)).view(1,-1)\n",
        "    out = self.layer1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.softmax(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "TqMtIp-7WOgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Model, loss function, optimizer등을 선언 #####\n",
        "model = CBOW(vocab_size, EMBEDDING_DIM)\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)"
      ],
      "metadata": {
        "id": "sy8_eM9sWO5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Train #####\n",
        "epoch = 100\n",
        "\n",
        "for i in tqdm(range(epoch)):\n",
        "  total_loss = 0\n",
        "  # Gradient 초기화\n",
        "  optimizer.zero_grad()\n",
        "  for context, target in data:\n",
        "    context_vector = make_context_vector(context, word_to_idx)\n",
        "    output = model(context_vector)\n",
        "    targets = torch.tensor([word_to_idx[target]])\n",
        "    total_loss += loss_function(output, targets)\n",
        "  print(f'epoch = {i}, loss = {total_loss}')\n",
        "  total_loss.backward()\n",
        "  optimizer.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "14b2e875277144408546d3b95631f3cc",
            "62f095cd98ef4bbdb68824183ea45b3c",
            "7527bb7e252941ccab46184edf529404",
            "c186d806be054d7ca8edcc4464d6d49e",
            "f8d34da8270d453aa6031c3309e33720",
            "fc4a7511266a4b5cac62ac691282ffe3",
            "8c4139e039124d26af51814cd25887c3",
            "20a0b4799e334706820103d2dc8f9224",
            "5617fd0617764c0b96f5efeedb4199f1",
            "210d86e55bae43e4898e773d8e2506b3",
            "08e661d603604a6cac33f4222697ee98"
          ]
        },
        "id": "KynI-K9FYHbI",
        "outputId": "9b692768-95ab-4b20-e912-2beb8c24c1a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14b2e875277144408546d3b95631f3cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0, loss = 297.2266845703125\n",
            "epoch = 1, loss = 288.53582763671875\n",
            "epoch = 2, loss = 280.43475341796875\n",
            "epoch = 3, loss = 272.7822570800781\n",
            "epoch = 4, loss = 265.3898010253906\n",
            "epoch = 5, loss = 258.0736389160156\n",
            "epoch = 6, loss = 250.82208251953125\n",
            "epoch = 7, loss = 243.57269287109375\n",
            "epoch = 8, loss = 236.2449951171875\n",
            "epoch = 9, loss = 228.90196228027344\n",
            "epoch = 10, loss = 221.5223846435547\n",
            "epoch = 11, loss = 214.08372497558594\n",
            "epoch = 12, loss = 206.60882568359375\n",
            "epoch = 13, loss = 199.13983154296875\n",
            "epoch = 14, loss = 191.69189453125\n",
            "epoch = 15, loss = 184.33592224121094\n",
            "epoch = 16, loss = 177.0757293701172\n",
            "epoch = 17, loss = 169.92478942871094\n",
            "epoch = 18, loss = 162.8783721923828\n",
            "epoch = 19, loss = 155.92266845703125\n",
            "epoch = 20, loss = 149.09378051757812\n",
            "epoch = 21, loss = 142.3462371826172\n",
            "epoch = 22, loss = 135.72491455078125\n",
            "epoch = 23, loss = 129.21017456054688\n",
            "epoch = 24, loss = 122.85318756103516\n",
            "epoch = 25, loss = 116.64346313476562\n",
            "epoch = 26, loss = 110.60317993164062\n",
            "epoch = 27, loss = 104.73157501220703\n",
            "epoch = 28, loss = 99.03832244873047\n",
            "epoch = 29, loss = 93.52172088623047\n",
            "epoch = 30, loss = 88.19029998779297\n",
            "epoch = 31, loss = 83.05876159667969\n",
            "epoch = 32, loss = 78.16986083984375\n",
            "epoch = 33, loss = 73.4874038696289\n",
            "epoch = 34, loss = 69.02437591552734\n",
            "epoch = 35, loss = 64.79159545898438\n",
            "epoch = 36, loss = 60.79436492919922\n",
            "epoch = 37, loss = 57.033145904541016\n",
            "epoch = 38, loss = 53.49527359008789\n",
            "epoch = 39, loss = 50.181190490722656\n",
            "epoch = 40, loss = 47.08511734008789\n",
            "epoch = 41, loss = 44.218170166015625\n",
            "epoch = 42, loss = 41.55742263793945\n",
            "epoch = 43, loss = 39.10495376586914\n",
            "epoch = 44, loss = 36.828712463378906\n",
            "epoch = 45, loss = 34.727455139160156\n",
            "epoch = 46, loss = 32.78788757324219\n",
            "epoch = 47, loss = 30.998321533203125\n",
            "epoch = 48, loss = 29.345951080322266\n",
            "epoch = 49, loss = 27.826330184936523\n",
            "epoch = 50, loss = 26.416948318481445\n",
            "epoch = 51, loss = 25.11667823791504\n",
            "epoch = 52, loss = 23.912784576416016\n",
            "epoch = 53, loss = 22.795513153076172\n",
            "epoch = 54, loss = 21.764257431030273\n",
            "epoch = 55, loss = 20.801342010498047\n",
            "epoch = 56, loss = 19.907007217407227\n",
            "epoch = 57, loss = 19.07249641418457\n",
            "epoch = 58, loss = 18.298410415649414\n",
            "epoch = 59, loss = 17.57198715209961\n",
            "epoch = 60, loss = 16.892187118530273\n",
            "epoch = 61, loss = 16.256261825561523\n",
            "epoch = 62, loss = 15.660820007324219\n",
            "epoch = 63, loss = 15.099088668823242\n",
            "epoch = 64, loss = 14.571346282958984\n",
            "epoch = 65, loss = 14.073416709899902\n",
            "epoch = 66, loss = 13.60507583618164\n",
            "epoch = 67, loss = 13.161020278930664\n",
            "epoch = 68, loss = 12.744695663452148\n",
            "epoch = 69, loss = 12.347467422485352\n",
            "epoch = 70, loss = 11.973644256591797\n",
            "epoch = 71, loss = 11.618346214294434\n",
            "epoch = 72, loss = 11.281183242797852\n",
            "epoch = 73, loss = 10.960380554199219\n",
            "epoch = 74, loss = 10.65539264678955\n",
            "epoch = 75, loss = 10.364913940429688\n",
            "epoch = 76, loss = 10.087774276733398\n",
            "epoch = 77, loss = 9.824557304382324\n",
            "epoch = 78, loss = 9.572153091430664\n",
            "epoch = 79, loss = 9.330963134765625\n",
            "epoch = 80, loss = 9.100895881652832\n",
            "epoch = 81, loss = 8.881050109863281\n",
            "epoch = 82, loss = 8.669463157653809\n",
            "epoch = 83, loss = 8.467093467712402\n",
            "epoch = 84, loss = 8.27332592010498\n",
            "epoch = 85, loss = 8.086400032043457\n",
            "epoch = 86, loss = 7.9071760177612305\n",
            "epoch = 87, loss = 7.73494815826416\n",
            "epoch = 88, loss = 7.568848133087158\n",
            "epoch = 89, loss = 7.410044193267822\n",
            "epoch = 90, loss = 7.255858898162842\n",
            "epoch = 91, loss = 7.108493804931641\n",
            "epoch = 92, loss = 6.9658050537109375\n",
            "epoch = 93, loss = 6.8281965255737305\n",
            "epoch = 94, loss = 6.695435523986816\n",
            "epoch = 95, loss = 6.567224502563477\n",
            "epoch = 96, loss = 6.443645477294922\n",
            "epoch = 97, loss = 6.323493480682373\n",
            "epoch = 98, loss = 6.20795202255249\n",
            "epoch = 99, loss = 6.09579610824585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### Inference #####\n",
        "\n",
        "test_data = ['case', 'of', 'one', 'word']\n",
        "test_vector = make_context_vector(test_data, word_to_idx)\n",
        "result = model(test_vector)\n",
        "print('Prediction : ', idx_to_word[torch.argmax(result[0]).item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3eS7JLiZtag",
        "outputId": "aaa01c24-8cf4-43c9-ca3d-c70020f8d784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction :  CBOW,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for child in model.children():\n",
        "  print(child)\n",
        "\n",
        "a,b,c,d,e = model.parameters()\n",
        "print(a.shape)\n",
        "print(b.shape)\n",
        "print(c.shape)\n",
        "print(d.shape)\n",
        "print(e.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1-VW9TcAiqQ",
        "outputId": "b80f8bff-a077-46e7-c947-5d1e95b08b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(72, 128)\n",
            "Linear(in_features=128, out_features=64, bias=True)\n",
            "ReLU()\n",
            "Linear(in_features=64, out_features=72, bias=True)\n",
            "LogSoftmax(dim=-1)\n",
            "torch.Size([72, 128])\n",
            "torch.Size([64, 128])\n",
            "torch.Size([64])\n",
            "torch.Size([72, 64])\n",
            "torch.Size([72])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Skip-gram\n",
        "----"
      ],
      "metadata": {
        "id": "BPnBxLCAdV-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_context_vector_skip(context, word_to_idx):\n",
        "  idxs = word_to_idx[context]\n",
        "  return torch.tensor(idxs , dtype = torch.long)\n",
        "\n",
        "def make_data_skip(sentence):\n",
        "  data_skip = []\n",
        "  for i in range(2, len(ex_sample)-2):\n",
        "    context = ex_sample[i]\n",
        "    target = [ex_sample[i-2], ex_sample[i-1], ex_sample[i+1], ex_sample[i+2]]\n",
        "    data_skip.append((context, target))\n",
        "  return data_skip\n",
        "\n",
        "data_skip = make_data_skip(ex_sample)"
      ],
      "metadata": {
        "id": "i91eWgs_cF0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 128\n",
        "EPOCHS = 200\n",
        "CONTEXT_SIZE = 4\n",
        "\n",
        "class Skip_gram(nn.Module):\n",
        "  def __init__(self,vocab_size, embedding_dim,context_size):\n",
        "    super(Skip_gram,self).__init__()\n",
        "\n",
        "    self.context_size = context_size\n",
        "    self.layer = nn.Sequential(\n",
        "                        nn.Embedding(vocab_size,embedding_dim),\n",
        "                        nn.Linear(embedding_dim, 64),\n",
        "                        nn.ReLU(),\n",
        "                        nn.Linear(64, vocab_size * context_size),\n",
        "                        nn.LogSoftmax(dim = -1)\n",
        "                               )\n",
        "  \n",
        "  def forward(self,inputs):\n",
        "    out = self.layer(inputs)\n",
        "    return out.view(self.context_size,vocab_size)"
      ],
      "metadata": {
        "id": "SSBdXrVadlnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_skip = Skip_gram(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE)\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(model_skip.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "juLZ1oV4fRIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(EPOCHS):\n",
        "  total_loss = 0\n",
        "  optimizer.zero_grad()\n",
        "  for context, target in data_skip:\n",
        "    context_vector = make_context_vector_skip(context,word_to_idx,)\n",
        "    output = model_skip(context_vector)\n",
        "    target = torch.tensor([word_to_idx[t] for t in target])\n",
        "    total_loss += loss_function(output,target)\n",
        "  print(f'epoch = {i}, loss = {total_loss}')\n",
        "  total_loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RfAa985fcL5",
        "outputId": "f8ee5fcd-4334-4b4b-ad1c-380852babe39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 0, loss = 387.027099609375\n",
            "epoch = 1, loss = 384.19879150390625\n",
            "epoch = 2, loss = 381.4392395019531\n",
            "epoch = 3, loss = 378.72174072265625\n",
            "epoch = 4, loss = 376.05694580078125\n",
            "epoch = 5, loss = 373.4172668457031\n",
            "epoch = 6, loss = 370.78033447265625\n",
            "epoch = 7, loss = 368.1426086425781\n",
            "epoch = 8, loss = 365.4821472167969\n",
            "epoch = 9, loss = 362.7930603027344\n",
            "epoch = 10, loss = 360.06988525390625\n",
            "epoch = 11, loss = 357.3033447265625\n",
            "epoch = 12, loss = 354.48583984375\n",
            "epoch = 13, loss = 351.6040344238281\n",
            "epoch = 14, loss = 348.6495056152344\n",
            "epoch = 15, loss = 345.6238708496094\n",
            "epoch = 16, loss = 342.52117919921875\n",
            "epoch = 17, loss = 339.3347473144531\n",
            "epoch = 18, loss = 336.0695495605469\n",
            "epoch = 19, loss = 332.7181701660156\n",
            "epoch = 20, loss = 329.28692626953125\n",
            "epoch = 21, loss = 325.7747497558594\n",
            "epoch = 22, loss = 322.1839904785156\n",
            "epoch = 23, loss = 318.5202331542969\n",
            "epoch = 24, loss = 314.78448486328125\n",
            "epoch = 25, loss = 310.9805603027344\n",
            "epoch = 26, loss = 307.1161804199219\n",
            "epoch = 27, loss = 303.1936340332031\n",
            "epoch = 28, loss = 299.2215576171875\n",
            "epoch = 29, loss = 295.2076416015625\n",
            "epoch = 30, loss = 291.15380859375\n",
            "epoch = 31, loss = 287.06842041015625\n",
            "epoch = 32, loss = 282.95135498046875\n",
            "epoch = 33, loss = 278.8106689453125\n",
            "epoch = 34, loss = 274.6507873535156\n",
            "epoch = 35, loss = 270.4761047363281\n",
            "epoch = 36, loss = 266.29632568359375\n",
            "epoch = 37, loss = 262.1115417480469\n",
            "epoch = 38, loss = 257.934814453125\n",
            "epoch = 39, loss = 253.76576232910156\n",
            "epoch = 40, loss = 249.60833740234375\n",
            "epoch = 41, loss = 245.47190856933594\n",
            "epoch = 42, loss = 241.36041259765625\n",
            "epoch = 43, loss = 237.278076171875\n",
            "epoch = 44, loss = 233.23146057128906\n",
            "epoch = 45, loss = 229.2273406982422\n",
            "epoch = 46, loss = 225.26473999023438\n",
            "epoch = 47, loss = 221.35366821289062\n",
            "epoch = 48, loss = 217.49502563476562\n",
            "epoch = 49, loss = 213.6944580078125\n",
            "epoch = 50, loss = 209.9519805908203\n",
            "epoch = 51, loss = 206.2783203125\n",
            "epoch = 52, loss = 202.67861938476562\n",
            "epoch = 53, loss = 199.15708923339844\n",
            "epoch = 54, loss = 195.7143096923828\n",
            "epoch = 55, loss = 192.35610961914062\n",
            "epoch = 56, loss = 189.0906982421875\n",
            "epoch = 57, loss = 185.9221954345703\n",
            "epoch = 58, loss = 182.85269165039062\n",
            "epoch = 59, loss = 179.89056396484375\n",
            "epoch = 60, loss = 177.04075622558594\n",
            "epoch = 61, loss = 174.30335998535156\n",
            "epoch = 62, loss = 171.68344116210938\n",
            "epoch = 63, loss = 169.17816162109375\n",
            "epoch = 64, loss = 166.78878784179688\n",
            "epoch = 65, loss = 164.5137939453125\n",
            "epoch = 66, loss = 162.35179138183594\n",
            "epoch = 67, loss = 160.30160522460938\n",
            "epoch = 68, loss = 158.3600311279297\n",
            "epoch = 69, loss = 156.52395629882812\n",
            "epoch = 70, loss = 154.79190063476562\n",
            "epoch = 71, loss = 153.16017150878906\n",
            "epoch = 72, loss = 151.62588500976562\n",
            "epoch = 73, loss = 150.18527221679688\n",
            "epoch = 74, loss = 148.83558654785156\n",
            "epoch = 75, loss = 147.5727996826172\n",
            "epoch = 76, loss = 146.3936309814453\n",
            "epoch = 77, loss = 145.29396057128906\n",
            "epoch = 78, loss = 144.27159118652344\n",
            "epoch = 79, loss = 143.32083129882812\n",
            "epoch = 80, loss = 142.43728637695312\n",
            "epoch = 81, loss = 141.61727905273438\n",
            "epoch = 82, loss = 140.8574676513672\n",
            "epoch = 83, loss = 140.15322875976562\n",
            "epoch = 84, loss = 139.4994659423828\n",
            "epoch = 85, loss = 138.8931427001953\n",
            "epoch = 86, loss = 138.3312530517578\n",
            "epoch = 87, loss = 137.8099365234375\n",
            "epoch = 88, loss = 137.3257598876953\n",
            "epoch = 89, loss = 136.87640380859375\n",
            "epoch = 90, loss = 136.45831298828125\n",
            "epoch = 91, loss = 136.06918334960938\n",
            "epoch = 92, loss = 135.70693969726562\n",
            "epoch = 93, loss = 135.36961364746094\n",
            "epoch = 94, loss = 135.0552215576172\n",
            "epoch = 95, loss = 134.761962890625\n",
            "epoch = 96, loss = 134.4876251220703\n",
            "epoch = 97, loss = 134.23130798339844\n",
            "epoch = 98, loss = 133.991943359375\n",
            "epoch = 99, loss = 133.7678680419922\n",
            "epoch = 100, loss = 133.5581512451172\n",
            "epoch = 101, loss = 133.3616485595703\n",
            "epoch = 102, loss = 133.17735290527344\n",
            "epoch = 103, loss = 133.00433349609375\n",
            "epoch = 104, loss = 132.841796875\n",
            "epoch = 105, loss = 132.68902587890625\n",
            "epoch = 106, loss = 132.54507446289062\n",
            "epoch = 107, loss = 132.40927124023438\n",
            "epoch = 108, loss = 132.28115844726562\n",
            "epoch = 109, loss = 132.16000366210938\n",
            "epoch = 110, loss = 132.04539489746094\n",
            "epoch = 111, loss = 131.93695068359375\n",
            "epoch = 112, loss = 131.8343505859375\n",
            "epoch = 113, loss = 131.73707580566406\n",
            "epoch = 114, loss = 131.64495849609375\n",
            "epoch = 115, loss = 131.55752563476562\n",
            "epoch = 116, loss = 131.4744873046875\n",
            "epoch = 117, loss = 131.39552307128906\n",
            "epoch = 118, loss = 131.32044982910156\n",
            "epoch = 119, loss = 131.24884033203125\n",
            "epoch = 120, loss = 131.1805877685547\n",
            "epoch = 121, loss = 131.11532592773438\n",
            "epoch = 122, loss = 131.05291748046875\n",
            "epoch = 123, loss = 130.9931640625\n",
            "epoch = 124, loss = 130.9359588623047\n",
            "epoch = 125, loss = 130.881103515625\n",
            "epoch = 126, loss = 130.8284454345703\n",
            "epoch = 127, loss = 130.77786254882812\n",
            "epoch = 128, loss = 130.72930908203125\n",
            "epoch = 129, loss = 130.6824493408203\n",
            "epoch = 130, loss = 130.63735961914062\n",
            "epoch = 131, loss = 130.5938720703125\n",
            "epoch = 132, loss = 130.55191040039062\n",
            "epoch = 133, loss = 130.5113983154297\n",
            "epoch = 134, loss = 130.47235107421875\n",
            "epoch = 135, loss = 130.4346160888672\n",
            "epoch = 136, loss = 130.39822387695312\n",
            "epoch = 137, loss = 130.3629913330078\n",
            "epoch = 138, loss = 130.3289337158203\n",
            "epoch = 139, loss = 130.29600524902344\n",
            "epoch = 140, loss = 130.26414489746094\n",
            "epoch = 141, loss = 130.23329162597656\n",
            "epoch = 142, loss = 130.20333862304688\n",
            "epoch = 143, loss = 130.17442321777344\n",
            "epoch = 144, loss = 130.14627075195312\n",
            "epoch = 145, loss = 130.11898803710938\n",
            "epoch = 146, loss = 130.09243774414062\n",
            "epoch = 147, loss = 130.06666564941406\n",
            "epoch = 148, loss = 130.0415802001953\n",
            "epoch = 149, loss = 130.01718139648438\n",
            "epoch = 150, loss = 129.99342346191406\n",
            "epoch = 151, loss = 129.97030639648438\n",
            "epoch = 152, loss = 129.94778442382812\n",
            "epoch = 153, loss = 129.92587280273438\n",
            "epoch = 154, loss = 129.90452575683594\n",
            "epoch = 155, loss = 129.8836669921875\n",
            "epoch = 156, loss = 129.8633575439453\n",
            "epoch = 157, loss = 129.8435516357422\n",
            "epoch = 158, loss = 129.8242645263672\n",
            "epoch = 159, loss = 129.80538940429688\n",
            "epoch = 160, loss = 129.78700256347656\n",
            "epoch = 161, loss = 129.76902770996094\n",
            "epoch = 162, loss = 129.75149536132812\n",
            "epoch = 163, loss = 129.7343292236328\n",
            "epoch = 164, loss = 129.71755981445312\n",
            "epoch = 165, loss = 129.70120239257812\n",
            "epoch = 166, loss = 129.68516540527344\n",
            "epoch = 167, loss = 129.6695098876953\n",
            "epoch = 168, loss = 129.65419006347656\n",
            "epoch = 169, loss = 129.63917541503906\n",
            "epoch = 170, loss = 129.62449645996094\n",
            "epoch = 171, loss = 129.61016845703125\n",
            "epoch = 172, loss = 129.5961151123047\n",
            "epoch = 173, loss = 129.58236694335938\n",
            "epoch = 174, loss = 129.5689239501953\n",
            "epoch = 175, loss = 129.5557098388672\n",
            "epoch = 176, loss = 129.54275512695312\n",
            "epoch = 177, loss = 129.5301055908203\n",
            "epoch = 178, loss = 129.51763916015625\n",
            "epoch = 179, loss = 129.5054931640625\n",
            "epoch = 180, loss = 129.49354553222656\n",
            "epoch = 181, loss = 129.48179626464844\n",
            "epoch = 182, loss = 129.47027587890625\n",
            "epoch = 183, loss = 129.45899963378906\n",
            "epoch = 184, loss = 129.4479217529297\n",
            "epoch = 185, loss = 129.43702697753906\n",
            "epoch = 186, loss = 129.42636108398438\n",
            "epoch = 187, loss = 129.41587829589844\n",
            "epoch = 188, loss = 129.4055938720703\n",
            "epoch = 189, loss = 129.39547729492188\n",
            "epoch = 190, loss = 129.38555908203125\n",
            "epoch = 191, loss = 129.37583923339844\n",
            "epoch = 192, loss = 129.36622619628906\n",
            "epoch = 193, loss = 129.35684204101562\n",
            "epoch = 194, loss = 129.3475799560547\n",
            "epoch = 195, loss = 129.3385009765625\n",
            "epoch = 196, loss = 129.32957458496094\n",
            "epoch = 197, loss = 129.32078552246094\n",
            "epoch = 198, loss = 129.31211853027344\n",
            "epoch = 199, loss = 129.30360412597656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = 'Skip-Gram'\n",
        "test_vector = make_context_vector_skip(test_data, word_to_idx)\n",
        "result_skip = model_skip(test_vector)\n",
        "print('Prediction : ', [idx_to_word[torch.argmax(r).item()] for r in result_skip])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEMcyVwCgMgD",
        "outputId": "9e219daa-5768-4e79-aaf8-5baf6fd61c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction :  ['CBOW', 'contrast,', 'learns', 'by']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for child in model_skip.children():\n",
        "  print(child)\n",
        "  \n",
        "a,b,c,d,e = model_skip.parameters()\n",
        "print(a.shape)\n",
        "print(b.shape)\n",
        "print(c.shape)\n",
        "print(d.shape)\n",
        "print(e.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vca1V42EHzAX",
        "outputId": "9d660c77-9eba-4315-b6a1-43580b1433bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Embedding(72, 128)\n",
            "  (1): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (2): ReLU()\n",
            "  (3): Linear(in_features=64, out_features=288, bias=True)\n",
            "  (4): LogSoftmax(dim=-1)\n",
            ")\n",
            "torch.Size([72, 128])\n",
            "torch.Size([64, 128])\n",
            "torch.Size([64])\n",
            "torch.Size([288, 64])\n",
            "torch.Size([288])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WlXikoYkG4Kb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}