{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvqvxC7_lYhu",
        "outputId": "1a7a94f8-3610-4d77-f3f8-cb6f54616359"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# google sentencepiece 설치\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wY-TLthlhHZ",
        "outputId": "feb5ab38-2c0f-49d7-f03b-b10bd1cc3af8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WSxsmzKxCwDc"
      },
      "outputs": [],
      "source": [
        "##### pytorch #####\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "##### 시각화 #####\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "\n",
        "##### 기본 모듈 #####\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import json\n",
        "import math\n",
        "import easydict\n",
        "from pprint import pprint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "##### 디버깅 #####\n",
        "import pdb\n",
        "\n",
        "##### cuda #####\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') # GPU 할당\n",
        "\n",
        "##### 경고무시 #####\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "import sentencepiece as spm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_file = \"/content/drive/MyDrive/2.Study/GPT/Data/kowiki.model\"\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnCGvMqjN-t7",
        "outputId": "e6bba6fa-da69-4172-ce65-b49c99594007"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = easydict.EasyDict({\n",
        "    \"n_dec_vocab\": len(vocab),\n",
        "    \"n_dec_seq\": 256,\n",
        "    \"n_layer\": 6,\n",
        "    \"d_hidn\": 256,\n",
        "    \"i_pad\": 0,\n",
        "    \"d_ff\": 1024,\n",
        "    \"n_head\": 4,\n",
        "    \"d_head\": 64,\n",
        "    \"dropout\": 0.1,\n",
        "    \"layer_norm_epsilon\": 1e-12\n",
        "                })"
      ],
      "metadata": {
        "id": "gev0o70RC4bR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Multi-head Attention\n",
        "---"
      ],
      "metadata": {
        "id": "yIxXT8FZEGfF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 주로 텍스트의 문맥 정보를 파악하기 위한 목적으로 사용\n",
        "\n",
        "- 입력된 문장을 여러개의 헤드로 나누고, 각 헤드가 문맥 정보를 학습\n",
        "\n",
        "- 이후 여러개의 헤드의 출력값을 연결(concatenate)하여 최종 출력값을 만들게 된다.\n",
        "\n",
        "- 위 과정을 통해 문장 내 단어들 사이의 의미론적 관계를 학습하고, 문장의 전체적인 의미를 파악할 수 있게 된다.\n",
        "\n",
        "- 현재 생성하려는 단어와 이전 단어들간의 의미론적 관계를 파악하여 다음 단어를 예측\n"
      ],
      "metadata": {
        "id": "Bmu9-b8cPdvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_hidn, n_head, d_head):\n",
        "        super().__init__()\n",
        "        self.d_hidn = d_hidn\n",
        "        self.n_head = n_head\n",
        "        self.d_head = d_head\n",
        "\n",
        "        self.W_Q = nn.Linear(d_hidn, n_head * d_head)\n",
        "        self.W_K = nn.Linear(d_hidn, n_head * d_head)\n",
        "        self.W_V = nn.Linear(d_hidn, n_head * d_head)\n",
        "        '''입력으로 들어온 차원(d_hidn)을 \n",
        "           헤드의 개수(n_head)와 헤드의 차원(d_head)으로 나누어 가중치 행렬을 생성 '''\n",
        "\n",
        "        self.scaled_dot_attn = ScaledDotProductAttention(d_head)\n",
        "        self.linear = nn.Linear(n_head * d_head, d_hidn)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        batch_size = Q.size(0)\n",
        "        \n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_head, self.d_head).transpose(1,2) # (bs, n_head, q_seq_len, d_head)\n",
        "        \n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.n_head, self.d_head).transpose(1,2) # (bs, n_head, k_seq_len, d_head)\n",
        "        \n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.n_head, self.d_head).transpose(1,2) # (bs, n_head, v_seq_len, d_head)\n",
        "\n",
        "        \n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_head, 1, 1) # (bs, n_head, q_seq_len, k_seq_len)\n",
        "\n",
        "        \n",
        "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
        "        '''context = Attention score를 기반으로 하는 v_s의 가중 합 (bs, n_head, q_seq_len, d_head)\n",
        "           attn_prob = 시퀀스에 대한 Attention Distribution (bs, n_head, q_seq_len, k_seq_len)'''\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_head * self.d_head) # (bs, n_head, q_seq_len, h_head * d_head)\n",
        "        \n",
        "        output = self.linear(context) # (bs, n_head, q_seq_len, e_embd)\n",
        "        \n",
        "        return output, attn_prob # (bs, q_seq_len, d_hidn), (bs, n_head, q_seq_len, k_seq_len)"
      ],
      "metadata": {
        "id": "h6GJDhQeEI_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Scaleed Dot Product Attention\n",
        "----"
      ],
      "metadata": {
        "id": "fRsqXdkvEP1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Query, Key, Value 3가지 벡터를 사용하여 주어진 문장을 이해하는데 사용\n",
        "\n",
        "- Query \n",
        "  - 각 단어가 다른 단어들과 어떤 관계를 맺고 있는지 나타내는 행렬\n",
        "\n",
        "  - 행렬을 구성하기 위해, 입력 seq의 각 단어의 임베딩 벡터를 입력으로 받고  \n",
        "    이를 선형 변환한 결과를 다시 하나의 벡터로 변환\n",
        "\n",
        "  - 이 벡터는 각 단어의 의미적인 정보를 담고 있는 행렬의 열로 사용된다.\n",
        "\n",
        "- Key \n",
        "\n",
        "  - 각 단어가 다른 단어들과 어떤 유사성을 가지고 있는지를 나타내는 행렬\n",
        "\n",
        "- Value \n",
        "\n",
        "  - 입력 seq의 각 단어에 대한 정보를 나태나는 행렬\n",
        "\n",
        "  - value 값은 Multi-head Attetntion에서 각 당너의 임베딩 벡터를 매핑하는데 사용\n",
        "\n",
        "\n",
        "Query값과 Key값의 내적 결과를 Softmax함수를 통해 정규화하여 각 단어에 대한 가중치를 구하고\n",
        "\n",
        "가중치를 이용해 value값을 Weighted Sum하여 Attention Context Vector를 계산\n",
        "\n",
        "이를 통해 입력 seq에서 각 단어에 대한 정보를 인코딩하는데 사용\n",
        "\n",
        "주어진 Query에 대해 가장 관련성이 높은 key-value 쌍을 선택하여 이를 통해 다음 단어를 예측하거나 문장을 생성"
      ],
      "metadata": {
        "id": "Y7tAhB1wMKUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, d_head):\n",
        "        super().__init__()\n",
        "        self.scale = 1 / (d_head ** 0.5)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        \n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale) # (bs, n_head, q_seq_len, k_seq_len)\n",
        "        scores.masked_fill_(attn_mask, -1e9)\n",
        "        \n",
        "        attn_prob = nn.Softmax(dim=-1)(scores) # (bs, n_head, q_seq_len, k_seq_len)\n",
        "        \n",
        "        context = torch.matmul(attn_prob, V) # (bs, n_head, q_seq_len, d_v)\n",
        "        \n",
        "        return context, attn_prob # (bs, n_head, q_seq_len, d_v), (bs, n_head, q_seq_len, v_seq_len)"
      ],
      "metadata": {
        "id": "BsteNMOAETRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Position-wise Feed Forward Net\n",
        "---"
      ],
      "metadata": {
        "id": "-hH3T28EPG5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AC8tIZ0wQnKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, d_hidn):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_hidn * 4, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.config.d_hidn * 4, out_channels=self.config.d_hidn, kernel_size=1)\n",
        "        self.active = F.gelu # 비선형성을 추가하고 모델의 표현력을 증가\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \n",
        "        output = self.active(self.conv1(inputs.transpose(1, 2))) # (bs, d_ff, n_seq)\n",
        "        \n",
        "        output = self.conv2(output).transpose(1, 2) # (bs, n_seq, d_hidn)\n",
        "        \n",
        "        return output # (bs, n_seq, d_hidn)"
      ],
      "metadata": {
        "id": "11E8zO1wPLx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# ETC\n",
        "---"
      ],
      "metadata": {
        "id": "ZFyYPKjQmvVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Position Encoding값을 구하는 함수 \n",
        "\n",
        "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
        "    \n",
        "    # 입력 위치와 임베딩 차원에 따라 해당 위치의 각도값을 계산\n",
        "    def cal_angle(position, i_hidn):\n",
        "        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
        "    \n",
        "    # 입력 위치에 따라 모든 임베딩 차원의 각도값 계산 \n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n",
        "\n",
        "    # seq길이와 임베딩 차원 수에 따라 시퀀스 길이 만큼 반복해서 생성된 값들을 저장\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n",
        "    \n",
        "    # 짝수 인덱스의 값들은 sin함수로 계산하고 홀수는 cos함수로 계산\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin \n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\n",
        "    '''sin, cos 함수는 시계열, 주기성이 있는 데이처를 처리할 때 사용되며 \n",
        "       생성된 값들은 특정한 주기를 가지게 되며 이를 통해 입력 seq내의 토큰 위치를 구분할 수 있게 됨\n",
        "       \n",
        "       즉, sin, cos를 사용해 위치 정보를 부여함으로써 \n",
        "       입력 seq 토큰 위치에 대한 정보를 학습하고 이를 활용해 문맥 정보를 파악할 수 있게 됨'''\n",
        "    return sinusoid_table"
      ],
      "metadata": {
        "id": "WIGbaSQLmw2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://paul-hyun.github.io/assets/2019-12-19/pad_mask.png'>"
      ],
      "metadata": {
        "id": "HPr8li-lp3id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# padding이 적용된 위치에 대한 mask를 생성하는 함수 \n",
        "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "\n",
        "    # i_pad와 일치하는 부분을 True, 아니면 False\n",
        "    pad_attn_mask = seq_k.data.eq(i_pad)\n",
        "\n",
        "    # seq_k와 같은 길이로 len_q까지 확장\n",
        "    pad_attn_mask= pad_attn_mask.unsqueeze(1).expand(batch_size, len_q, len_k)\n",
        "    return pad_attn_mask"
      ],
      "metadata": {
        "id": "wLgxhUX9nDoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://paul-hyun.github.io/assets/2019-12-19/decoder_mask.png'>"
      ],
      "metadata": {
        "id": "xAegO_J2p62R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# attention decoder mask \n",
        "def get_attn_decoder_mask(seq):\n",
        "\n",
        "    # Decoder의 입력 시퀀스와 동일한 크기의 tensor를 생성하고 모든 요소를 1로 채움\n",
        "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
        "    \n",
        "    # 대각선 기준 위쪽 삼각형만 남기고 아래쪽 삼각형을 0으로 만듬\n",
        "    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n",
        "    \n",
        "    # Decoder의 입력 시퀀스를 대각선 기준으로 위쪽 삼각형 = 0, 아래쪽 삼각형 = 1로 채운 이진 행렬 \n",
        "    return subsequent_mask"
      ],
      "metadata": {
        "id": "D_czF6jim738"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "# Decoder Layer\n",
        "----"
      ],
      "metadata": {
        "id": "JayijZsdDElS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://paul-hyun.github.io/assets/2019-12-30/decoder.png'>"
      ],
      "metadata": {
        "id": "YbpzHHFfDHWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "  \n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "\n",
        "    self.self_attn = MultiHeadAttention(self.config)\n",
        "    self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    '''입력 tensor의 마지막 차원을 기준으로 계산된 평균과 표준편차를 이용하여 정규화된 tensor를 출력\n",
        "       학습 안정화 / Gradient vanishing / 일반화 성능향상에 장점이존재'''\n",
        "       \n",
        "    self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "    self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "  \n",
        "  def forward(self, dec_inputs, self_attn_mask):\n",
        "      \n",
        "    self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)\n",
        "    # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq)\n",
        "\n",
        "    self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\n",
        "    \n",
        "    \n",
        "    ffn_outputs = self.pos_ffn(self_att_outputs) # (bs, n_dec_seq, d_hidn)\n",
        "    ffn_outputs = self.layer_norm3(self_att_outputs + ffn_outputs)\n",
        "    \n",
        "    return ffn_outputs, self_attn_prob    \n",
        "    # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)"
      ],
      "metadata": {
        "id": "Sc1ob6MnC6yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Decoder\n",
        "---"
      ],
      "metadata": {
        "id": "FQdz4EwmmgsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.dec_emb = nn.Embedding(self.config.n_dec_vocab, self.config.d_hidn)\n",
        "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_dec_seq + 1, self.config.d_hidn))\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, dec_inputs):\n",
        "        positions = torch.arange(dec_inputs.size(1), device=dec_inputs.device, dtype=dec_inputs.dtype).expand(dec_inputs.size(0), dec_inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = dec_inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "    \n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        dec_outputs = self.dec_emb(dec_inputs) + self.pos_emb(positions)\n",
        "\n",
        "\n",
        "        dec_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)\n",
        "\n",
        "        dec_attn_decoder_mask = get_attn_decoder_mask(dec_inputs)\n",
        "\n",
        "        dec_self_attn_mask = torch.gt((dec_attn_pad_mask + dec_attn_decoder_mask), 0)\n",
        "\n",
        "        self_attn_probs = []\n",
        "        for layer in self.layers:\n",
        "           \n",
        "            dec_outputs, self_attn_prob = layer(dec_outputs, dec_self_attn_mask)\n",
        "            self_attn_probs.append(self_attn_prob)\n",
        "\n",
        "        return dec_outputs, self_attn_probs"
      ],
      "metadata": {
        "id": "Hd3_SZOxlWrc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}