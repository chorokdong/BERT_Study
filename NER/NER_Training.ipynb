{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1bgLQBjK2hq_H8gXR6Csb_tPtGg5PDrWe","authorship_tag":"ABX9TyPPIYQ9utRXhM0G7OM1Dcx5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"fe5d8c09474549eca477224f19b0d1cc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b30d6468f154ed8a999f3c105eea1f3","IPY_MODEL_44336a68c04c4c0199c48f930fbcdbd4","IPY_MODEL_15a7946876284c528293b90152dfbb4c"],"layout":"IPY_MODEL_951d57662821422a96806e740d29df60"}},"5b30d6468f154ed8a999f3c105eea1f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8920eb01f8ed4754bd37b76b7f12a734","placeholder":"​","style":"IPY_MODEL_4e467a6f352c4f60ac033e573bcc5731","value":"Downloading: 100%"}},"44336a68c04c4c0199c48f930fbcdbd4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a8c64851cc04db8ada121bc54a7e160","max":249928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4dd8824d443b4367981553889da835d6","value":249928}},"15a7946876284c528293b90152dfbb4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7125a60899304558a95f6574d634089d","placeholder":"​","style":"IPY_MODEL_dc0a03aa3509497c977c6cacf4cc4d1e","value":" 250k/250k [00:00&lt;00:00, 2.79MB/s]"}},"951d57662821422a96806e740d29df60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8920eb01f8ed4754bd37b76b7f12a734":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e467a6f352c4f60ac033e573bcc5731":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a8c64851cc04db8ada121bc54a7e160":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dd8824d443b4367981553889da835d6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7125a60899304558a95f6574d634089d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc0a03aa3509497c977c6cacf4cc4d1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"697e98cc480a4470a13e717bd4eb9f6b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e626223c94f4f19a2ff08047d8786a1","IPY_MODEL_7800defedf7b4598bfb605d25404bee7","IPY_MODEL_cb48af909bbb4e37951176d4e9b0b80d"],"layout":"IPY_MODEL_fab0d9d85d624a36b3de433703839bfc"}},"8e626223c94f4f19a2ff08047d8786a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08f924a8a239492d9162382354309476","placeholder":"​","style":"IPY_MODEL_7ba96b49026643d9ba73b64e15717040","value":"Downloading: 100%"}},"7800defedf7b4598bfb605d25404bee7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f888445b4244713a77ace1586ff47c5","max":49,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b13c0311bc64bb5a4167a7f779b0cfd","value":49}},"cb48af909bbb4e37951176d4e9b0b80d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aec029407c73442a821dc3a30ec28b26","placeholder":"​","style":"IPY_MODEL_a0b37dce251f44cf90dad73754dd1ce6","value":" 49.0/49.0 [00:00&lt;00:00, 1.68kB/s]"}},"fab0d9d85d624a36b3de433703839bfc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08f924a8a239492d9162382354309476":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ba96b49026643d9ba73b64e15717040":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f888445b4244713a77ace1586ff47c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b13c0311bc64bb5a4167a7f779b0cfd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aec029407c73442a821dc3a30ec28b26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0b37dce251f44cf90dad73754dd1ce6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38111c7a83ed4db3a5c4faa6ebb06d2d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2399f32eb29743caa84b2ef76fe465de","IPY_MODEL_dadd933f55e54247a305da0837a21a4a","IPY_MODEL_93a9a666ff834a1488ca1e1390fe8727"],"layout":"IPY_MODEL_78821832b3d843a485e037dd25719da5"}},"2399f32eb29743caa84b2ef76fe465de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_136b4e02bf7c424dbb2b7ee9c62e0d94","placeholder":"​","style":"IPY_MODEL_e5e2eaa96b514d15931eb6e5755f8ccd","value":"Downloading: 100%"}},"dadd933f55e54247a305da0837a21a4a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_68430414247f4a98a28b284910241881","max":619,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85c0f5991c1b4f308471d5810ebc6dce","value":619}},"93a9a666ff834a1488ca1e1390fe8727":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8426080c1fc04720a24b94ece5c0993a","placeholder":"​","style":"IPY_MODEL_5c5e317be2df4d64841bc032e4fa7bb7","value":" 619/619 [00:00&lt;00:00, 28.3kB/s]"}},"78821832b3d843a485e037dd25719da5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"136b4e02bf7c424dbb2b7ee9c62e0d94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5e2eaa96b514d15931eb6e5755f8ccd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68430414247f4a98a28b284910241881":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85c0f5991c1b4f308471d5810ebc6dce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8426080c1fc04720a24b94ece5c0993a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c5e317be2df4d64841bc032e4fa7bb7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9123ce7905d74fefb8769bdfb7481f4e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f9083dd1e2b844098ae99c8e7048a9d0","IPY_MODEL_f1e247a2a6db49e981e48e30f2137ce6","IPY_MODEL_ef9af0e634504f90a8d160cd4c0a63a4"],"layout":"IPY_MODEL_b553260512bf444ea97931d0e5a5d2a8"}},"f9083dd1e2b844098ae99c8e7048a9d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2911ab83e544710b65301d14a54ab95","placeholder":"​","style":"IPY_MODEL_639637bf902c4b939a9d456050f0af8a","value":"Downloading: 100%"}},"f1e247a2a6db49e981e48e30f2137ce6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1105ada641714a2abab08002ac39be3f","max":438218004,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a4a595a7cda4938aaad3be277e93283","value":438218004}},"ef9af0e634504f90a8d160cd4c0a63a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6726d07cfea47bf8680ae9ab21ffc15","placeholder":"​","style":"IPY_MODEL_9bd4296027bb4a8b8b78e877369e6506","value":" 438M/438M [00:11&lt;00:00, 57.4MB/s]"}},"b553260512bf444ea97931d0e5a5d2a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2911ab83e544710b65301d14a54ab95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"639637bf902c4b939a9d456050f0af8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1105ada641714a2abab08002ac39be3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a4a595a7cda4938aaad3be277e93283":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c6726d07cfea47bf8680ae9ab21ffc15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bd4296027bb4a8b8b78e877369e6506":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["---\n","# install & load\n","---"],"metadata":{"id":"yuP6J9LnRmAA"}},{"cell_type":"markdown","source":["[참고블로그](https://ratsgo.github.io/nlpbook/docs/ner/train/#%EC%BD%94%EB%93%9C7-%EB%A7%90%EB%AD%89%EC%B9%98-%EB%8B%A4%EC%9A%B4%EB%A1%9C%EB%93%9C)"],"metadata":{"id":"g_6p_KVZnTaM"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install ratsnlp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Ca5vMbXNuEN","executionInfo":{"status":"ok","timestamp":1678888984109,"user_tz":-540,"elapsed":20900,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"d8dd90f0-fd80-49c0-d628-54368a4d4a81"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.0-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.2 tokenizers-0.13.2 transformers-4.27.0\n"]}]},{"cell_type":"code","source":["##### pytorch #####\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset, RandomSampler\n","\n","\n","##### 시각화 #####\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import seaborn as sns \n","\n","##### 기본 모듈 #####\n","import pandas as pd\n","import numpy as np\n","import os\n","import random\n","import json\n","import math\n","import easydict\n","from pprint import pprint\n","from sklearn.model_selection import train_test_split\n","from tqdm.notebook import tqdm\n","\n","##### 디버깅 #####\n","import pdb\n","\n","##### cuda #####\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') # GPU 할당\n","\n","##### 경고무시 #####\n","import warnings\n","warnings.filterwarnings(action='ignore')\n","\n","\n","import re"],"metadata":{"id":"obSnC40OL_EL","executionInfo":{"status":"ok","timestamp":1678889369588,"user_tz":-540,"elapsed":3,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["class Args:\n","  pretrained_model_name = 'beomi/kcbert-base'\n","  downstream_corpus_name =  'ner'\n","  downstream_model_dir = '/content/drive/MyDrive/2.Study/NER'\n","  downstream_corpus_root_dir = '/content/drive/MyDrive/2.Study/NER'\n","  downstream_task_name = 'named-entity-recognition'\n","  train_data = '/content/drive/MyDrive/2.Study/NER/train.txt'\n","  val_data = '/content/drive/MyDrive/2.Study/NER/val.txt'\n","  batch_size = 16\n","  learning_rate = 5e-5\n","  max_seq_length = 64\n","  epochs = 5\n","  seed = 7\n","  force_download = False\n","  overwrite_cache = False\n","\n","args = Args()  "],"metadata":{"id":"6lw_7ti0QAM_","executionInfo":{"status":"ok","timestamp":1678889857070,"user_tz":-540,"elapsed":2,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["from ratsnlp.nlpbook.ner import NERTrainArguments\n","from ratsnlp import nlpbook\n","\n","nlpbook.download_downstream_dataset(args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OEGWW2B9jx4u","executionInfo":{"status":"ok","timestamp":1678889185102,"user_tz":-540,"elapsed":2363,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"1ec68dd4-60e8-4ed6-eeab-d29f1e484b56"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: 100%|██████████| 17.9M/17.9M [00:00<00:00, 54.3MB/s]\n","Downloading: 100%|██████████| 1.13M/1.13M [00:00<00:00, 41.3MB/s]\n"]}]},{"cell_type":"markdown","source":["---\n","# Tokenizer\n","---"],"metadata":{"id":"Qftd3T_ARgyt"}},{"cell_type":"code","source":["from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained(\n","    args.pretrained_model_name,\n","    do_lower_case=False,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["fe5d8c09474549eca477224f19b0d1cc","5b30d6468f154ed8a999f3c105eea1f3","44336a68c04c4c0199c48f930fbcdbd4","15a7946876284c528293b90152dfbb4c","951d57662821422a96806e740d29df60","8920eb01f8ed4754bd37b76b7f12a734","4e467a6f352c4f60ac033e573bcc5731","0a8c64851cc04db8ada121bc54a7e160","4dd8824d443b4367981553889da835d6","7125a60899304558a95f6574d634089d","dc0a03aa3509497c977c6cacf4cc4d1e","697e98cc480a4470a13e717bd4eb9f6b","8e626223c94f4f19a2ff08047d8786a1","7800defedf7b4598bfb605d25404bee7","cb48af909bbb4e37951176d4e9b0b80d","fab0d9d85d624a36b3de433703839bfc","08f924a8a239492d9162382354309476","7ba96b49026643d9ba73b64e15717040","7f888445b4244713a77ace1586ff47c5","2b13c0311bc64bb5a4167a7f779b0cfd","aec029407c73442a821dc3a30ec28b26","a0b37dce251f44cf90dad73754dd1ce6","38111c7a83ed4db3a5c4faa6ebb06d2d","2399f32eb29743caa84b2ef76fe465de","dadd933f55e54247a305da0837a21a4a","93a9a666ff834a1488ca1e1390fe8727","78821832b3d843a485e037dd25719da5","136b4e02bf7c424dbb2b7ee9c62e0d94","e5e2eaa96b514d15931eb6e5755f8ccd","68430414247f4a98a28b284910241881","85c0f5991c1b4f308471d5810ebc6dce","8426080c1fc04720a24b94ece5c0993a","5c5e317be2df4d64841bc032e4fa7bb7"]},"id":"EfR7hDX3RfQy","executionInfo":{"status":"ok","timestamp":1678889195700,"user_tz":-540,"elapsed":2237,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"51e49ab9-cdb1-471d-95e8-0e854208e3ac"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/250k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe5d8c09474549eca477224f19b0d1cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"697e98cc480a4470a13e717bd4eb9f6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/619 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38111c7a83ed4db3a5c4faa6ebb06d2d"}},"metadata":{}}]},{"cell_type":"markdown","source":["- @dataclass 데코레이터를 사용해주는 이유?\n","\n","  - 데코레이터를 정의하지 않으면 클래스의 모든 속성을 별도로 정의해야 하므로 코드의 길이가 더 길어짐\n","        class NERExample:\n","          def __init__(text, label)\n","            self.text = text\n","            self.label = label\n","  - 데코레이터를 사용하면 속성을 정의하고 생성자를 구현하는 작업이 간단해지므로 코드의 가독성이 높아짐\n","\n","  - 또한 @dataclass를 사용하면 클래스의 인스턴스에 대한 여러 유용한 메서드들이 자동으로 생성됨              "],"metadata":{"id":"Fj-F3ItJU6Ly"}},{"cell_type":"markdown","source":["---\n","# Dataset & DataLoader\n","---"],"metadata":{"id":"VxFhIJU9obEZ"}},{"cell_type":"code","source":["from typing import List, Optional\n","from dataclasses import dataclass\n","\n","@dataclass\n","class NERExample:\n","    text: str\n","    label: Optional[str] = None\n","\n","@dataclass\n","class NERFeatures:\n","    input_ids: List[int]\n","    attention_mask: Optional[List[int]] = None\n","    token_type_ids: Optional[List[int]] = None\n","    label_ids: Optional[List[int]] = None\n","\n","NER_CLS_TOKEN = \"[CLS]\"\n","NER_SEP_TOKEN = \"[SEP]\"\n","NER_PAD_TOKEN = \"[PAD]\"\n","NER_MASK_TOKEN = \"[MASK]\"\n","NER_PAD_ID = 2\n","\n","class NERCorpus:\n","\n","    def __init__(self, args: args):\n","        self.args = args\n","\n","    # 파일에서 text와 label값을 추출하여 객체를 생성\n","    def get_examples(self, data_root_path, mode):\n","        data_fpath = os.path.join(data_root_path, f\"{mode}.txt\")\n","        examples = []\n","        for line in open(data_fpath, \"r\", encoding=\"utf-8\").readlines():\n","            text, label = line.split(\"\\u241E\")\n","            examples.append(NERExample(text=text, label=label))\n","        return examples\n","\n","    '''self.args 에 저장된 경로와 파일 이름 정보를 이용하여 \n","       label_map.txt 파일을 읽어오거나, 파일이 없으면 새로 생성 \n","       이때 train.txt 파일에서 regex_ner 패턴에 해당하는 문자열에서 추출한 \n","       ner_tag 값을 이용하여 labels 리스트를 생성하고, 이를 label_map.txt 파일에 저장\n","    '''\n","    def get_labels(self):\n","        label_map_path = os.path.join(\n","            self.args.downstream_model_dir, \"label_map.txt\",)\n","        \n","        if not os.path.exists(label_map_path):\n","            os.makedirs(self.args.downstream_model_dir, exist_ok=True)\n","            ner_tags = []\n","            regex_ner = re.compile('<(.+?):[A-Z]{3}>')\n","            train_corpus_path = os.path.join(\n","                self.args.downstream_corpus_root_dir,\n","                self.args.downstream_corpus_name,\n","                \"train.txt\",\n","            )\n","            target_sentences = [line.split(\"\\u241E\")[1].strip()\n","                                for line in open(train_corpus_path, \"r\", encoding=\"utf-8\").readlines()]\n","            for target_sentence in target_sentences:\n","                regex_filter_res = regex_ner.finditer(target_sentence)\n","                for match_item in regex_filter_res:\n","                    ner_tag = match_item[0][-4:-1]\n","                    if ner_tag not in ner_tags:\n","                        ner_tags.append(ner_tag)\n","            b_tags = [f\"B-{ner_tag}\" for ner_tag in ner_tags]\n","            i_tags = [f\"I-{ner_tag}\" for ner_tag in ner_tags]\n","            labels = [NER_CLS_TOKEN, NER_SEP_TOKEN, NER_PAD_TOKEN, NER_MASK_TOKEN, \"O\"] + b_tags + i_tags\n","            with open(label_map_path, \"w\", encoding=\"utf-8\") as f:\n","                for tag in labels:\n","                    f.writelines(tag + \"\\n\")\n","        else:\n","            labels = [tag.strip() for tag in open(label_map_path, \"r\", encoding=\"utf-8\").readlines()]\n","        return labels\n","\n","    @property\n","    # 라벨의 개수\n","    def num_labels(self):\n","        return len(self.get_labels())"],"metadata":{"id":"wdH2myaRR3WG","executionInfo":{"status":"ok","timestamp":1678889195700,"user_tz":-540,"elapsed":4,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# 주어진 문장을 토큰화하고, NER 태그를 찾아서 해당 태그에 대한 정보를 추출\n","def _process_target_sentence(\n","        tokens: List[str],\n","        origin_sentence: str,\n","        target_sentence: str,\n","        max_length: int,\n","        label_map: dict,\n","        tokenizer: BertTokenizer,\n","        cls_token_at_end: Optional[bool] = False,\n","):\n","    \"\"\"\n","    target_sentence = \"―<효진:PER> 역의 <김환희:PER>(<14:NOH>)가 특히 인상적이었다.\"\n","    tokens = [\"―\", \"효\", \"##진\", \"역\", \"##의\", \"김\", \"##환\", \"##희\",\n","              \"(\", \"14\", \")\", \"가\", \"특히\", \"인상\", \"##적이\", \"##었다\", \".\"]\n","    label_sequence = ['O', 'B-PER', 'I-PER', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'O',\n","                      'B-NOH', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","    \"\"\"\n","\n","    ################# [UNK] 토큰을 처리하는 부분 #################\n","    if \"[UNK]\" in tokens:\n","        processed_tokens = []\n","        \n","        # 입력 문장을 기본 토크나이저를 이용해 토큰화\n","        basic_tokens = tokenizer.basic_tokenizer.tokenize(origin_sentence)\n","        # basic_tokens에서 하나씩 꺼내서 \n","        for basic_token in basic_tokens:\n","            # 현재 토큰(basic_token)을 서브 토크나이저를 이용해 다시 토큰화\n","            current_tokens = tokenizer.tokenize(basic_token)\n","            '''why? 왜 다시 서브토크나이저를 이용해 재토큰화를 하는가?\n","               \n","               [UNK] 토큰이 포핟묀 경우 해당 토큰을 서브 토큰으로 분리하기 위함\n","               이를 분리해야 모델이 이해할 수 있기 때문'''\n","\n","            # 서브 토큰에도 [UNK] 토큰이 있다면 기본 토큰 그대로를 processed_tokens 리스트에 추가\n","            # 즉, 서브 토큰일 사용했음에도 [UNK] 토큰이 존재한다면 그냥 사용하겠다는 의미\n","            if \"[UNK]\" in current_tokens:\n","                processed_tokens.append(basic_token)\n","            # [UNK] 토큰이 없다면... 서브 토큰 리스트를 processed_tokens 리스트에 추가                 \n","            else:\n","                processed_tokens.extend(current_tokens)\n","    else:\n","        processed_tokens = tokens\n","    #############################################################\n","\n","    # 토큰화된 결과(processed_tokens)의 각 토큰의 시작 인덱스와 전체 길이를 계산하기 위해 초기화\n","    prefix_sum_of_token_start_index, sum = [0], 0\n","    for i, token in enumerate(processed_tokens):\n","        # 토큰이 서브 토큰인 경우(##으로 시작) ##를 제외한 실제 토큰의 길이를 계산해서 sum에 추가\n","        if token.startswith(\"##\"):\n","            sum += len(token) - 2\n","        else:\n","            sum += len(token)\n","        prefix_sum_of_token_start_index.append(sum)\n","\n","    # 정규표현식 <ner_text:ner_tag> 형식으로 된 개체명 태그를 찾기 위한 패턴\n","    regex_ner = re.compile('<(.+?):[A-Z]{3}>')  # NER Tag가 2자리 문자면 {3} -> {2}로 변경 (e.g. LOC -> LC) 인경우\n","    # target_sentence에서 개체명 태그를 찾기\n","    regex_filter_res = regex_ner.finditer(target_sentence.replace(\" \", \"\"))\n","\n","    list_of_ner_tag = [] # 개체명 태그 \n","    list_of_ner_text = [] # 개체명 텍스트\n","    list_of_tuple_ner_start_end = [] # 개체명의 시작과 끝 인덱스 \n","\n","    count_of_match = 0 # 정규식에 매칭되는 문자열의 개수를 세는 변수\n","    # 정규식에서 매칭되는 문자열을 하나씩 순회\n","    for match_item in regex_filter_res:\n","        ner_tag = match_item[0][-4:-1]  # <4일간:DUR> -> DUR\n","        ner_text = match_item[1]  # <4일간:DUR> -> 4일간\n","        \n","        # <,:,>,NER 태그명(3자리)를 제거한 값의 시작 인덱스와 끝 인덱스 계산\n","        start_index = match_item.start() - 6 * count_of_match \n","        end_index = match_item.end() - 6 - 6 * count_of_match\n","        '''이전 매칭에서 <, :, NER 태그 이름, > 총 6개의 문자열이 사용되었으므로, \n","          새로운 매칭에서는 해당 문자열의 개수를 곱해 이전 매칭에서 사용된 문자열을 제거할 수 있다. \n","          이를 통해 각 NER 태그의 시작 위치와 끝 위치를 정확하게 계산할 수 있다.'''\n","        list_of_ner_tag.append(ner_tag)\n","        list_of_ner_text.append(ner_text)\n","        list_of_tuple_ner_start_end.append((start_index, end_index))\n","        count_of_match += 1\n","\n","    ###################### 토큰의 시작 위치; 정보를 사용해 레이블 시퀀스를 생성하는 코드 ######################\n","    '''반복문에서 현재 토큰과 그 위치를 가져와 entity_index가 NER 태그 정보의 길이보다 작을 때까지 반복하며, \n","       이전 엔티티의 범위보다 현재 토큰의 시작 위치가 큰 경우 다음 엔티티를 가져온다. \n","       그리고 토큰의 시작 위치가 현재 엔티티의 범위 안에 포함되는 경우에는 엔티티의 태그를 생성하고, \n","       현재 엔티티가 B 태그인지 아닌지 여부를 is_entity_still_B 변수로 확인하며, 레이블 시퀀스에 추가 \n","       포함되지 않는 경우에는 O 태그를 생성하고, is_entity_still_B 변수를 True로 초기화.'''\n","    label_sequence = [] # 레이블 시퀀스 초기화\n","    entity_index = 0 # 엔티티 인덱스 초기화\n","    is_entity_still_B = True # 엔티티가 첫번째 토큰에서 시작하는지 여부\n","\n","    for tup in zip(processed_tokens, prefix_sum_of_token_start_index):\n","        token, index = tup\n","\n","        if entity_index < len(list_of_tuple_ner_start_end):\n","            start, end = list_of_tuple_ner_start_end[entity_index]\n","\n","            if end < index:  # 엔티티 범위보다 현재 seq pos가 더 크면 다음 엔티티를 꺼내서 체크\n","                is_entity_still_B = True\n","                entity_index = entity_index + 1 if entity_index + 1 < len(list_of_tuple_ner_start_end) else entity_index\n","                start, end = list_of_tuple_ner_start_end[entity_index]\n","\n","            if start <= index and index < end:  # <13일:DAT>까지 -> ('▁13', 10, 'B-DAT') ('일까지', 12, 'I-DAT') 이런 경우가 포함됨, 포함 안시키려면 토큰의 length도 계산해서 제어해야함\n","                entity_tag = list_of_ner_tag[entity_index]\n","                if is_entity_still_B is True:\n","                    entity_tag = 'B-' + entity_tag\n","                    label_sequence.append(entity_tag)\n","                    is_entity_still_B = False\n","                else:\n","                    entity_tag = 'I-' + entity_tag\n","                    label_sequence.append(entity_tag)\n","            else:\n","                is_entity_still_B = True\n","                entity_tag = 'O'\n","                label_sequence.append(entity_tag)\n","        else:\n","            entity_tag = 'O'\n","            label_sequence.append(entity_tag)\n","    #############################################################################################\n","\n","    # max_length 보다 크면 max_length -2 값까지만 자름\n","    label_sequence = label_sequence[:max_length - 2]\n","\n","    # True라면 [CLS], [SEP] 토큰 끝에 추가 \n","    # False라면 [CLS], [SEP] 토큰 앞에 추가\n","    if cls_token_at_end:\n","        label_sequence = label_sequence + [NER_CLS_TOKEN, NER_SEP_TOKEN]\n","    else:\n","        label_sequence = [NER_CLS_TOKEN] + label_sequence + [NER_SEP_TOKEN]\n","\n","    # padding\n","    pad_length = max(max_length - len(label_sequence), 0)\n","    pad_sequence = [NER_PAD_TOKEN] * pad_length\n","    label_sequence += pad_sequence\n","\n","    # encoding\n","    label_ids = [label_map[label] for label in label_sequence]\n","    return label_ids"],"metadata":{"id":"FlL2yJOfX-in","executionInfo":{"status":"ok","timestamp":1678889195700,"user_tz":-540,"elapsed":3,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from transformers.tokenization_utils_base import PaddingStrategy, TruncationStrategy\n","from filelock import FileLock\n","\n","# 모델 학습을 위해 입력 문장을 토큰화하고 레이블을 처리하여 input 값으로 사용할 수 있는 feature로 변환하는 함수\n","def _convert_examples_to_ner_features(\n","        examples: List[NERExample],\n","        tokenizer: BertTokenizer,\n","        args: args,\n","        label_list: List[str],\n","        cls_token_at_end: Optional[bool] = False,\n","    ):\n","        \"\"\"\n","        `cls_token_at_end` define the location of the CLS token:\n","                - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n","                - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n","        \"\"\"\n","        # 레이블의 문자열을 정수로 매핑\n","        label_map = {label: i for i, label in enumerate(label_list)}\n","        # 레입ㄹ의 정수를 문자열로 매핑\n","        id_to_label = {i: label for i, label in enumerate(label_list)}\n","\n","        # 입력 토큰, 마스크, 세그먼트, 레이블 인덱스 저장\n","        features = [] \n","        for example in examples:\n","            tokens = tokenizer.tokenize(example.text)\n","            inputs = tokenizer._encode_plus(\n","                tokens,\n","                max_length=args.max_seq_length,\n","                truncation_strategy=TruncationStrategy.LONGEST_FIRST,\n","                padding_strategy=PaddingStrategy.MAX_LENGTH,\n","            )\n","            label_ids = _process_target_sentence(\n","                tokens=tokens,\n","                origin_sentence=example.text,\n","                target_sentence=example.label,\n","                max_length=args.max_seq_length,\n","                label_map=label_map,\n","                tokenizer=tokenizer,\n","                cls_token_at_end=cls_token_at_end,\n","            )\n","            features.append(NERFeatures(**inputs, label_ids=label_ids))\n","\n","        return features"],"metadata":{"id":"nqtynB5QXt5t","executionInfo":{"status":"ok","timestamp":1678889195700,"user_tz":-540,"elapsed":3,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["class NERDataset(Dataset):\n","\n","    def __init__(\n","            self,\n","            args: args,\n","            tokenizer: BertTokenizer,\n","            corpus: NERCorpus,\n","            mode: Optional[str] = \"train\",\n","            convert_examples_to_features_fn=_convert_examples_to_ner_features,\n","    ):\n","        if corpus is not None:\n","            self.corpus = corpus\n","        else:\n","            raise KeyError(\"corpus is not valid\")\n","        if not mode in [\"train\", \"val\", \"test\"]:\n","            raise KeyError(f\"mode({mode}) is not a valid split name\")\n","        # Load data features from cache or dataset file\n","        cached_features_file = os.path.join(\n","            args.downstream_corpus_root_dir,\n","            args.downstream_corpus_name,\n","            \"cached_{}_{}_{}_{}_{}\".format(\n","                mode,\n","                tokenizer.__class__.__name__,\n","                str(args.max_seq_length),\n","                args.downstream_corpus_name,\n","                args.downstream_task_name,\n","            ),\n","        )\n","\n","        # Make sure only the first process in distributed training processes the dataset,\n","        # and the others will use the cache.\n","        lock_path = cached_features_file + \".lock\"\n","        with FileLock(lock_path):\n","\n","            if os.path.exists(cached_features_file) and not args.overwrite_cache:\n","                self.features = torch.load(cached_features_file)\n","\n","            else:\n","                corpus_path = os.path.join(\n","                    args.downstream_corpus_root_dir,\n","                    args.downstream_corpus_name,\n","                )\n","                examples = self.corpus.get_examples(corpus_path, mode)\n","                self.features = convert_examples_to_features_fn(\n","                    examples,\n","                    tokenizer,\n","                    args,\n","                    label_list=self.corpus.get_labels(),\n","                )\n","                torch.save(self.features, cached_features_file)\n","\n","\n","    def __len__(self):\n","        return len(self.features)\n","\n","    def __getitem__(self, i):\n","        return self.features[i]\n","\n","    def get_labels(self):\n","        return self.corpus.get_labels()"],"metadata":{"id":"b39vPxSNXkP7","executionInfo":{"status":"ok","timestamp":1678889195701,"user_tz":-540,"elapsed":4,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["- 원본 문장 : ―효진 역의 김환희(14)가 특히 인상적이었다.\n","- 레이블한 문장 : ―<효진:PER> 역의 <김환희:PER>(<14:NOH>)가 특히 인상적이었다.\n","\n","  - PER(인명)으로 레이블링된 효진은 tokens 기준 세번째 토큰(효)부터 네번째 토큰(##진)인 걸 확인할 수 있습니다. 이에 labels에는 세번째 토큰과 네번째 토큰이 PER(인명)이 되도록 합니다. 단 여기에서 B-는 해당 태그의 시작(Begin), I-는 해당 태그의 시작이 아님(Inside)이라는 뜻을 가집니다.\n","\n","  - PER(인명)으로 레이블링된 김환희는 일곱번째 토큰(김)부터 아홉번째 토큰(##희)인 걸 알 수 있습니다. 이에 labels에는 일곱번째 토큰과 아홉번째 토큰이 PER(인명)이 되도록 합니다. 마찬가지로 14의 경우 labels의 열한번째 토큰이 NOH(기타 수량표현)이 되도록 만들었습니다. 한편 labels에서 O는 outside의 약자로 개체명이 아닌 부분을 의미합니다.\n","\n","  - 이후 NERDataset은 여기에 인덱싱 작업을 수행하여 input_ids, attention_mask, token_type_ids, labels를 만듭니다. input_ids는 tokens에 인덱싱을 수행한 결과이며 attention_mask는 tokens 각각의 해당 토큰이 패딩인지(0) 아닌지(1)를 나타냅니다. token_type_ids는 세그먼트(segment) 정보로 기본값은 모두 0으로 넣습니다.\n","\n","\n","- label_ids은 labels의 각 개체명 태그(B-PER, I-PER 등)를 정수로 바꾼 결과\n","\n","- 개체명 인식을 위한 BERT 모델의 입력은 input_ids, attention_mask, token_type_ids이 되며, 출력은 labels가 되도록 합니다. "],"metadata":{"id":"5Jqy714Dm4Nk"}},{"cell_type":"code","source":["corpus = NERCorpus(args)\n","train_dataset = NERDataset(\n","    args=args,\n","    corpus=corpus,\n","    tokenizer=tokenizer,\n","    mode=\"train\",\n",")"],"metadata":{"id":"0MDgsIn_UYTK","executionInfo":{"status":"ok","timestamp":1678889245506,"user_tz":-540,"elapsed":49809,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=args.batch_size,\n","    sampler=RandomSampler(train_dataset, replacement=False),\n","    collate_fn=nlpbook.data_collator,\n","    drop_last=False,\n","    num_workers=1,\n",")"],"metadata":{"id":"5jAuDwTgXXh0","executionInfo":{"status":"ok","timestamp":1678889388799,"user_tz":-540,"elapsed":355,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["value = next(iter(train_dataloader))\n","print(value)\n","print(value['labels'].shape)\n","print(value['input_ids'].shape)\n","print(value['attention_mask'].shape)\n","print(value['token_type_ids'].shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BA7I5LY6mtWF","executionInfo":{"status":"ok","timestamp":1678889802075,"user_tz":-540,"elapsed":508,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"4f3a7a06-58e8-483e-9efb-866c36b91183"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["{'labels': tensor([[ 0,  9, 19,  ...,  2,  2,  2],\n","        [ 0,  4,  4,  ...,  4,  4,  1],\n","        [ 0,  8, 18,  ...,  4,  4,  1],\n","        ...,\n","        [ 0,  4,  4,  ...,  2,  2,  2],\n","        [ 0,  4,  4,  ...,  2,  2,  2],\n","        [ 0,  4,  4,  ...,  4,  4,  1]]), 'input_ids': tensor([[    2, 28413, 22903,  ...,     0,     0,     0],\n","        [    2, 18368,  8791,  ...,  4474,  8292,     3],\n","        [    2,  9530,  8242,  ...,  1410,  4700,     3],\n","        ...,\n","        [    2,  3108,  4307,  ...,     0,     0,     0],\n","        [    2,     6, 10747,  ...,     0,     0,     0],\n","        [    2,   198, 28005,  ...,  4272,  1492,     3]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        [1, 1, 1,  ..., 1, 1, 1],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 1, 1, 1]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0]])}\n","torch.Size([16, 64])\n","torch.Size([16, 64])\n","torch.Size([16, 64])\n","torch.Size([16, 64])\n"]}]},{"cell_type":"markdown","source":["- RandomSampler \n","  - 데이터셋에서 무작위로 데이터를추출하여 미니배치 생성\n","\n","  - 데이터를 잘 섞어주는 역할을 하며, 학습 시간을 줄이고 높은 정확도를 얻을 수 있음\n","\n","- SequentialSampler\n","  - 데이터셋의 인덱스를 처음부터 끝까지 순서대로 반환\n","\n","  - 데이터셋을 읽는 순서가 중요할 때 사용 (ex, 시계열 데이터)\n","\n","  "],"metadata":{"id":"aCz-pOsRoxlc"}},{"cell_type":"code","source":["from torch.utils.data import SequentialSampler\n","val_dataset = NERDataset(\n","    args=args,\n","    corpus=corpus,\n","    tokenizer=tokenizer,\n","    mode=\"val\",\n",")\n","val_dataloader = DataLoader(\n","    val_dataset,\n","    batch_size=args.batch_size,\n","    sampler=SequentialSampler(val_dataset),\n","    collate_fn=nlpbook.data_collator,\n","    drop_last=False,\n","    num_workers=1,\n",")"],"metadata":{"id":"Zy-RW6ztmzcm","executionInfo":{"status":"ok","timestamp":1678889860110,"user_tz":-540,"elapsed":775,"user":{"displayName":"김건국","userId":"04251633153705627950"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["---\n","# Model\n","---"],"metadata":{"id":"Z7GEgu9DolK5"}},{"cell_type":"code","source":["from transformers import BertConfig, BertForTokenClassification\n","pretrained_model_config = BertConfig.from_pretrained(\n","    args.pretrained_model_name,\n","    num_labels=corpus.num_labels,\n",")\n","model = BertForTokenClassification.from_pretrained(\n","        args.pretrained_model_name,\n","        config=pretrained_model_config,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["9123ce7905d74fefb8769bdfb7481f4e","f9083dd1e2b844098ae99c8e7048a9d0","f1e247a2a6db49e981e48e30f2137ce6","ef9af0e634504f90a8d160cd4c0a63a4","b553260512bf444ea97931d0e5a5d2a8","c2911ab83e544710b65301d14a54ab95","639637bf902c4b939a9d456050f0af8a","1105ada641714a2abab08002ac39be3f","2a4a595a7cda4938aaad3be277e93283","c6726d07cfea47bf8680ae9ab21ffc15","9bd4296027bb4a8b8b78e877369e6506"]},"id":"r7t7wiOjntyH","executionInfo":{"status":"ok","timestamp":1678890071352,"user_tz":-540,"elapsed":14939,"user":{"displayName":"김건국","userId":"04251633153705627950"}},"outputId":"a16dfe01-ca54-43c8-9e3b-face14803c43"},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9123ce7905d74fefb8769bdfb7481f4e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","source":["---\n","# Train\n","---"],"metadata":{"id":"Bc2GmW6nqFAk"}},{"cell_type":"code","source":[],"metadata":{"id":"Xs5rltzEqGQL"},"execution_count":null,"outputs":[]}]}